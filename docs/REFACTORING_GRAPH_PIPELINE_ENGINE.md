# Рефакторинг движка графовых пайплайнов YggDrasil (полная спецификация)

**Версия:** 2.0  
**Резюме.** Документ задаёт цели, детальную архитектуру оркестратора, автосборку циклов денойзинга для **любых** диффузионных моделей (включая все пайплайны и компоненты из Hugging Face Diffusers и кастомные), полный охват адаптеров (ControlNet, IP-Adapter, T2I-Adapter, Motion Adapter и все прочие из Diffusers), универсальные солверы/шелдулеры, недиффузионные пайплайны широкого профиля, детализацию обучения и единый интерфейс через **InferencePipeline** / **TrainingPipeline** (без отдельного класса CombinedPipeline: комбинированный пайплайн = тот же пайплайн, инициализированный списком или словарём графов). Реализация должна опираться на лучшие практики и максимальную надёжность кода.

---

## 1. Цели и границы

### 1.1 Цели

- **Единый оркестратор сборки** с явными фазами и полной автоматизацией: пользователь добавляет узлы; подключения, циклы денойзинга и проброс портов выполняет движок.
- **Универсальность по модальностям и моделям:** поддержка **любых** модальностей (изображение, видео, аудио, текст, мульти) и **любых** диффузионных архитектур — в том числе все пайплайны и компоненты из репозитория [Hugging Face Diffusers](https://github.com/huggingface/diffusers), а также **кастомные модели, которых ещё не существует** (расширяемость через регистрацию без изменения ядра).
- **Полный охват адаптеров:** не только ControlNet и IP-Adapter, но и T2I-Adapter, Motion Adapter (AnimateDiff), и все прочие адаптеры, реализованные в Diffusers и в экосистеме (включая будущие). Базой для перечня и контрактов служит репозиторий Diffusers.
- **Универсальные солверы:** поддержка всех типов шелдулеров из Diffusers (Euler, DDIM, DPM, Flow Matching, LCMS, и т.д.) и возможность регистрации кастомных; автосборка цикла денойзинга под выбранный тип шага.
- **Недиффузионные пайплайны:** не только детекция, сегментация, классификация, оценка глубины и позы, но и супер-разрешение, извлечение эмбеддингов, стилизация, маскирование, оценка углов/нормалей и любые иные задачи, встречающиеся при сборке сложных сцен и постобработке.
- **Расширяемость** под мировые модели (world models) и сложные сцены через те же примитивы графа и оркестратора.
- **Обучение:** детально проработанная поддержка обучения всего графа, подграфа или отдельных узлов (заморозка/разморозка, loss-узлы, backward, чекпоинты).
- **Единый интерфейс пайплайна:** комбинированные сценарии реализуются **только** через **InferencePipeline** и **TrainingPipeline**. Отдельного класса «CombinedPipeline» нет: при инициализации пайплайна передаётся либо один граф, либо **список графов**, либо **словарь графов**; в последних двух случаях пайплайн ведёт себя как комбинированный (последовательно, по связям или параллельно). Тот же API (`__call__`, `to(device)`, обучение) для одиночного и комбинированного варианта.

### 1.2 Нецели

- Замена формата конфигов (YAML/OmegaConf остаются, при необходимости расширяются).
- Полная ломка обратной совместимости: миграция вызовов с сохранением семантики; при необходимости — deprecation с явным предупреждением.

### 1.3 Эталон: Hugging Face Diffusers

> **Поддержка любых решений Diffusers в архитектуре YggDrasil.**  
> Должны поддерживаться **все** пайплайны, адаптеры и солверы из Hugging Face Diffusers и экосистемы — но реализованные в **стиле, архитектуре и движке YggDrasil** (граф, оркестратор, единый контракт блоков, без прямого использования классов Diffusers внутри пайплайна). Любое решение из Diffusers воспроизводимо средствами YggDrasil.

В качестве **эталона перечня** пайплайнов, адаптеров и солверов используется репозиторий [huggingface/diffusers](https://github.com/huggingface/diffusers):

- **Пайплайны:** все семейства (Stable Diffusion 1.x/2.x/XL, SD3, ControlNet, Flux, Kandinsky, DeepFloyd IF, AnimateDiff, I2VGen-XL, CogVideoX, AudioLDM, MusicLDM, и т.д.) — движок должен позволять собирать графы, эквивалентные любому такому пайплайну, и поддерживать кастомные архитектуры.
- **Адаптеры:** ControlNet (все варианты), IP-Adapter, T2I-Adapter, Motion Adapter (AnimateDiff), и любые другие адаптеры из Diffusers и сообщества; контракт адаптера унифицирован (подключение к циклу денойзинга, порты, опциональные входы).
- **Солверы/шелдулеры:** EulerDiscreteScheduler, EulerAncestralDiscreteScheduler, DDIMScheduler, DPMSolverMultistepScheduler, DPMSolverSinglestepScheduler, FlowMatchEulerDiscreteScheduler, LCMScheduler, UniPC, DEIS, Heun, LMS, и т.д. — каждый тип должен иметь описание шага (step graph) для автосборки цикла.

---

## 2. Архитектура: слои и оркестратор

```
┌─────────────────────────────────────────────────────────────────────────────┐
│  Пользовательский API                                                         │
│  InferencePipeline(graph) / InferencePipeline(graphs=[...]) /                │
│  InferencePipeline(graphs={"stage1": g1, ...}, connections=...)               │
│  add_node(name, type=…), replace_node, connect, __call__(**kwargs)            │
└─────────────────────────────────────────────────────────────────────────────┘
                                        │
                                        ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  GraphBuildOrchestrator (единая точка сборки)                                 │
│  Состояние сборки, фазы, реестр ролей, разрешители, шаблоны циклов/шагов     │
└─────────────────────────────────────────────────────────────────────────────┘
                    │
        ┌───────────┼───────────┬───────────────┐
        ▼           ▼           ▼               ▼
┌──────────────┐ ┌──────────────┐ ┌─────────────────┐ ┌─────────────────────┐
│ RoleRegistry  │ │ TargetResolver│ │ LoopTemplates   │ │ AdapterBindingRules  │
│ (роль→правила)│ │ (куда вставить│ │ (denoise loop   │ │ (controlnet, ip,    │
│               │ │ узел/цикл)   │ │ по backbone +   │ │  t2i, motion, …)     │
│               │ │              │ │ solver type)    │ │                      │
└──────────────┘ └──────────────┘ └─────────────────┘ └─────────────────────┘
                                        │
                                        ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  ComputeGraph (узлы, рёбра, graph_inputs/outputs, топологический порядок)     │
└─────────────────────────────────────────────────────────────────────────────┘
                                        │
                                        ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  GraphExecutor (inference / training, кэш по узлам, строгость портов)       │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 3. Класс оркестратора (GraphBuildOrchestrator): детальное проектирование

Оркестратор — **единственная** компонента, принимающая решения о том, куда подключить узел, когда создать цикл денойзинга, когда отложить связь до появления целевого узла. Текущего краткого описания недостаточно; ниже — полная спецификация класса.

### 3.1 Ответственность

- При вызове `add_node(name, block_or_type, ...)` определять **роль** узла (по типу блока или по явной роли).
- Решать **целевой узел/граф** для подключения (conditioner → цепочка condition; adapter → внутренний граф узла-цикла; backbone → подмена на цикл денойзинга; codec → выход цикла; solver → внутрь цикла).
- Вести **очередь отложенных действий** (например адаптеры, ожидающие появления узла-цикла); при появлении цикла — обрабатывать очередь и подключать адаптеры к inner graph.
- В фазе **материализации** (при `to(device)` или при явном `build()`) создавать циклы из backbone, подставлять шаблон шага по типу solver, пробрасывать входы графа для опциональных портов (control_image_*, ip_image).
- **Валидировать** граф после сборки (связность, обязательные порты, отсутствие дубликатов имён).

### 3.2 Состояние оркестратора (BuildState)

- `graph`: ссылка на собираемый `ComputeGraph`.
- `denoise_loop_node_name`: имя узла-цикла денойзинга (если уже создан); `None` до появления первого backbone.
- `deferred_adapter_bindings`: список `(node_name, adapter_block, role)` — адаптеры, ожидающие появления цикла.
- `phase`: текущая фаза сборки (`REGISTER` | `RESOLVE` | `DEFER_OR_CONNECT` | `MATERIALIZE` | `VALIDATE`).
- `metadata`: метаданные графа (modality, base_model, latent_channels, и т.д.), используемые при выборе шаблона и привязке адаптеров.

### 3.3 Фазы сборки (жизненный цикл)

| Фаза | Когда | Действия |
|------|--------|-----------|
| **REGISTER** | `add_node` вызван | Регистрация узла в графе, определение роли (RoleRegistry), сохранение в состоянии. |
| **RESOLVE** | Сразу после REGISTER | TargetResolver по роли и текущему состоянию графа возвращает: (target_graph, target_node, target_port) или флаг «отложить». Для backbone — решение «создать цикл и подменить узел на цикл». |
| **DEFER_OR_CONNECT** | После RESOLVE | Если цель найдена — сразу добавить ребро/вложить узел (для адаптера — во inner graph цикла). Если цель ещё не существует (например цикл) — добавить в `deferred_adapter_bindings` или в очередь отложенных подключений conditioner/codec. |
| **MATERIALIZE** | При `graph.to(device)` или явном `orchestrator.materialize()` | Создание циклов из зарегистрированных backbone (подмена на LoopSubGraph с шаблоном шага по solver); обработка очереди отложенных адаптеров (вставка в inner graph, проброс входов); установка метаданных цикла (use_euler_init_sigma, latent_channels, и т.д.). |
| **VALIDATE** | После MATERIALIZE или по запросу | Проверка: все обязательные входы графа имеют источник; нет «висячих» портов; имена входов адаптеров (control_image_*, ip_image) уникальны и задекларированы в graph_inputs. |

### 3.4 Методы оркестратора (публичный API)

- `register_node(name, block_or_type, **kwargs) -> None`  
  Вызывается из `ComputeGraph.add_node` при `auto_connect=True`. Выполняет фазы REGISTER → RESOLVE → DEFER_OR_CONNECT; при необходимости откладывает связь.

- `materialize() -> None`  
  Выполняет фазу MATERIALIZE: создание циклов, обработка отложенных адаптеров, проброс портов. Вызывается из `graph.to(device)` или из пайплайна перед первым запуском.

- `validate() -> List[str]`  
  Выполняет фазу VALIDATE; возвращает список предупреждений/ошибок (пустой список — успех).

- `get_state() -> BuildState`  
  Возвращает текущее состояние (для отладки и тестов).

- `set_metadata(key, value)` / `get_metadata(key)`  
  Установка/чтение метаданных, влияющих на выбор шаблона и привязку (например `base_model`, `modality`).

### 3.5 Зависимости оркестратора

- **RoleRegistry:** маппинг `block_type` / `role` → правила (target_node hint, target_port, нужен ли цикл, список портов для graph_input).
- **TargetResolver:** функция `(role, build_state) -> (target_graph, target_node, target_port) | DEFER`.
- **LoopTemplates:** по паре (backbone_type, solver_type) или по метаданным (modality, prediction_type) возвращает шаблон inner graph цикла (step graph + связи latents/timestep/condition).
- **AdapterBindingRules:** для каждого типа адаптера (controlnet, ip_adapter, t2i_adapter, motion_adapter, …) — куда вставлять узел (inner graph цикла), к какому порту backbone подключать (adapter_features / image_prompt_embeds), какое имя graph_input пробрасывать (control_image, ip_image, и т.д.).

Реализация должна быть **расширяемой**: регистрация новых ролей, новых типов адаптеров и новых шаблонов циклов без изменения ядра оркестратора (плагины/реестры).

---

## 4. Автосборка цикла денойзинга для любой модели

Требование: цикл денойзинга собирается **автоматически** не только для уже реализованных в YggDrasil пайплайнов (SD 1.5, SDXL, SD3, FLUX), но и для **всех** пайплайнов, реализованных в Diffusers, и для **кастомных** архитектур (включая пока не существующие).

### 4.1 Общий алгоритм

1. Пользователь добавляет узел с ролью **backbone** (UNet2D, UNet3D, Transformer2D, DiT, и т.д.).
2. Оркестратор не добавляет backbone как один узел; он **подменяет** его на узел типа **LoopSubGraph** (цикл денойзинга).
3. Внутри цикла: граф одного **шага** (step graph). Шаг состоит из: (опционально) scale_model_input → вызов backbone (sample, timestep, condition, adapter_features, …) → вызов solver.step(model_output, sample, timestep) → выход next_latents.
4. Шаблон шага выбирается по **типу solver** и по **метаданным** (prediction_type: epsilon / v_prediction / sample; архитектура: unet_2d / transformer_2d; наличие CFG и т.д.). Реестр **LoopTemplates** возвращает граф шага для данной комбинации.
5. Для известных семейств (SD, SDXL, SD3, FLUX, AnimateDiff, Kandinsky, AudioLDM, и т.д.) в движке регистрируются шаблоны шага (или они выводятся из Diffusers при импорте). Для неизвестной комбинации используется **generic** шаблон: backbone(sample, timestep, condition) → solver.step(…) → next_latents; при необходимости пользователь регистрирует свой шаблон.

### 4.2 Источники шаблонов

- **Встроенные:** шаблоны для Euler, DDIM, PNDM, FlowMatch (SD3), batched CFG (SDXL), single-batch (SD 1.5), уже имеющиеся в коде.
- **Из Diffusers:** при использовании `InferencePipeline.from_diffusers(pipe)` или при регистрации пайплайна из Diffusers — извлечение типа scheduler и формата шага (step signature) и маппинг в внутренний шаблон шага.
- **Пользовательские:** регистрация функции `(metadata) -> ComputeGraph` (step graph) для кастомной архитектуры.

### 4.3 Метаданные цикла

Выводятся из конфига backbone/codec и из реестра по `base_model` / `modality`: `latent_channels`, `spatial_scale_factor`, `use_euler_init_sigma`, `use_scheduler_timesteps`, `prediction_type`, `num_train_timesteps`. Они передаются в цикл и в solver, чтобы поведение совпадало с Diffusers (и с кастомными моделями при корректной регистрации).

---

## 5. Адаптеры: полный охват

В движке поддерживаются **все** адаптеры, имеющие смысл в контексте диффузионных пайплайнов. Базовый перечень ориентирован на Diffusers и экосистему.

### 5.1 Типы адаптеров (обязательный минимум и расширение)

| Тип | Назначение | Порты в графе | Подключение к циклу |
|-----|------------|----------------|----------------------|
| **ControlNet** | Пространственный контроль (depth, canny, pose, segmentation, …) | control_image (или control_image_<name>), conditioning_scale | adapter_features backbone во inner graph |
| **IP-Adapter** | Образец по изображению (стиль, объект) | ip_image, ip_adapter_scale | image_prompt_embeds / adapter_features (по архитектуре) |
| **T2I-Adapter** | Облегчённый контроль (depth, canny, sketch, …) | control_image, adapter_scale | adapter_features backbone |
| **Motion Adapter** (AnimateDiff) | Тайм-консистентная анимация в видео | (встраивается в backbone как motion modules) | как часть backbone или отдельный узел в step graph |
| **Другие** | LoRA, DoRA, Hypernetwork, Textual Inversion, и т.д. | по типу | LoRA/веса — в слот backbone; остальные по правилам AdapterBindingRules |

Любой новый адаптер из Diffusers (или кастомный) должен быть **реализуем** путём: (1) реализации блока, совместимого с AbstractAdapter/AbstractInnerModule, (2) регистрации в AdapterBindingRules (куда вставлять, какой порт, какое имя входа).

### 5.2 Единое правило подключения

- Оркестратор при добавлении узла с ролью adapter (или inner_module) определяет тип адаптера (controlnet, ip_adapter, t2i_adapter, motion_adapter, …).
- Если узел-цикл уже есть — сразу вставить узел адаптера во inner graph цикла и соединить с backbone по правилу; пробросить верхнеуровневый вход (control_image / ip_image / …) в граф.
- Если узла-цикла ещё нет — добавить запись в `deferred_adapter_bindings`; при материализации (создании цикла) обработать очередь и выполнить вставку и проброс.
- Имена входов для нескольких ControlNet: однозначно `control_image_<node_name>`; маппинг control_type → имя входа строится при материализации и кэшируется.

### 5.3 Чистота входов

- Перед выполнением графа все опциональные входы (control_image*, ip_image, …), объявленные в graph_inputs, но не переданные в вызове, явно устанавливаются в `None`.
- Масштаб IP-Adapter применяется только при фактически переданном `ip_image`.

---

## 6. Солверы (шелдулеры)

Поддержка **всех** типов солверов, реализованных в Diffusers, плюс возможность регистрации кастомных.

- **Дискретные:** EulerDiscreteScheduler, EulerAncestralDiscreteScheduler, DDIMScheduler, DDIMInverseScheduler, DPMSolverMultistepScheduler, DPMSolverSinglestepScheduler, KDPM2DiscreteScheduler, KDPM2AncestralDiscreteScheduler, HeunDiscreteScheduler, LMSDiscreteScheduler, UniPCMultistepScheduler, DEISMultistepScheduler, и т.д.
- **Flow matching:** FlowMatchEulerDiscreteScheduler (SD3, Flux) и аналоги.
- **LCM:** LCMScheduler и варианты.

В графе остаётся только понятие **Solver** (без отдельной сущности Scheduler): solver инкапсулирует расписание шагов и один шаг `step(model_output, sample, timestep, ...) -> prev_sample`. Для совместимости с Diffusers конфиг шелдулера копируется в solver; при импорте из Diffusers тип шелдулера маппится на зарегистрированный тип solver и шаблон шага.

---

## 7. Недиффузионные пайплайны (широкий класс)

Граф может **не содержать** ни одного backbone/цикла денойзинга. Оркестратор в таком случае только соединяет узлы по правилам ролей.

### 7.1 Роли и задачи (расширенный список)

- **Сегментация:** segmenter (семантическая, instance, панорамная); выход — маски (одна или много), с возможностью выбора/склейки масок.
- **Детекция:** detector (объекты, лица, ключевые точки); выход — боксы, классы, confidence.
- **Классификация:** classifier; выход — классы, эмбеддинги.
- **Глубина / геометрия:** depth_estimator, normal_estimator, pose_estimator; выход — карты глубины, нормалей, скелеты.
- **Супер-разрешение:** super_resolution (недиффузионные модели, например ESRGAN-style); вход/выход — изображение.
- **Стиль / эмбеддинги:** style_encoder, feature_extractor; выход — векторы или карты признаков.
- **Обработка сигналов:** audio_processor, video_processor (обрезка, конкатенация, микс аудио/видео).
- **Произвольный процессор:** processor, outer_module — обёртка над любой внешней моделью или API.

Общий контракт: входы/выходы узлов — тензоры или словари с согласованными ключами (image, mask, latents, audio, video, …); один и тот же GraphExecutor выполняет граф и для диффузии, и для недиффузионных задач.

---

## 8. Обучение: детальная проработка

### 8.1 Режимы

- **Inference:** граф выполняется в `torch.no_grad()`, градиенты не требуются.
- **Training:** граф выполняется без `no_grad()`; градиенты сохраняются для узлов, помеченных как обучаемые.

### 8.2 Выбор обучаемых параметров

- **train_nodes:** список имён узлов (или масок вида `stage0/denoise_loop.backbone`, `stage0/lora`) — только эти узлы имеют `requires_grad=True`; остальные замораживаются.
- **freeze_nodes:** альтернатива — перечислить замораживаемые; остальные обучаемые (если не указано иное).
- Параметры задаются при создании TrainingPipeline или через конфиг (train_stages / train_nodes).

### 8.3 Loss-узлы

- Узлы с ролью **loss**: принимают prediction (и опционально target, mask, weights) и возвращают скаляр loss.
- Оркестратор при наличии loss-узла обеспечивает, что порядок выполнения графа допускает backward от выхода loss до всех обучаемых узлов.
- TrainingPipeline ожидает либо явный выход `loss`, либо имя узла с выходом loss; вызов `backward()` по этому выходу.

### 8.4 Чекпоинты и состояние

- Сохранение/загрузка состояния: весь граф или только указанные узлы (например только LoRA, только adapter). Совместимость с форматом Diffusers (где применимо).
- Ступенчатое обучение: заморозка части графа, дообучение другой части без изменения интерфейса пайплайна.

---

## 9. Единый пайплайн: InferencePipeline и TrainingPipeline (без отдельного CombinedPipeline)

Комбинированный пайплайн **не** является отдельным классом. **InferencePipeline** и **TrainingPipeline** принимают:

- **Один граф:** `InferencePipeline(graph)` или `InferencePipeline.from_graph(graph)` — обычный одиночный граф.
- **Список графов:** `InferencePipeline(graphs=[g1, g2, g3])` — этапы выполняются **последовательно**; выход этапа N передаётся во вход этапа N+1 по соглашению портов (например output → input).
- **Словарь графов:** `InferencePipeline(graphs={"stage1": g1, "stage2": g2}, connections=...)` — пользователь может задать **связи между этапами** (какие выходы какого этапа куда подаются). По умолчанию — линейная цепочка по порядку ключей.

Поведение:

- При списке/словаре пайплайн внутренне строит граф верхнего уровня, узлы которого — AbstractStage (каждая стадия — граф); рёбра задаются links/connections. Вызов `pipe(**kwargs)` выполняет этот граф (последовательно или по DAG этапов).
- **Параллельное выполнение:** при задании групп этапов (например `parallel_groups=[["branch_a", "branch_b"]]`) этапы внутри группы выполняются параллельно (один общий вход раздаётся, результаты объединяются по правилу merge). Реализация — через план выполнения (DAG с параллельными ветками) в исполнителе.
- **Единый функциональный базис:** те же методы `__call__`, `to(device)`, загрузка/сохранение весов; любой граф-пайплайн можно использовать как этап в таком «комбинированном» сценарии без смены API.

Инициализация из конфига (YAML с `kind: combined_pipeline`, stages + links) уже даёт граф пайплайна с узлами-AbstractStage; этот граф передаётся в `InferencePipeline(graph)` или `TrainingPipeline(graph)`. **Отдельный класс CombinedPipeline не вводится и не должен присутствовать в коде:** вся функциональность «комбинированного» пайплайна реализуется исключительно через сигнатуры `InferencePipeline` / `TrainingPipeline`, принимающие один граф, список графов или словарь графов.

---

## 9A. Gradio-интерфейс (динамический UI)

Пользовательский интерфейс на базе **Gradio** — минимум **5 вкладок**, единый принцип: сборка пайплайна → материализация → работа с ним на вкладках Inference и Train с **динамическими** блоками параметров под состав графа.

### 9A.1 Вкладки

| # | Вкладка | Назначение |
|---|---------|------------|
| 1 | **Inference** | Инференс: параметры генерации (prompt, num_steps, seed, и т.д.) и **динамические блоки параметров** для каждого узла в материализованном графе (например ControlNet: control_image, conditioning_scale; IP-Adapter: ip_image, ip_adapter_scale). |
| 2 | **Pipeline** | Сборка пайплайна: выбор и добавление блоков из каталога; построение графа (узлы, связи); кнопка **Materialize** — материализация графа; после материализации пайплайн доступен на вкладках Inference и Train. |
| 3 | **Train** | Обучение: параметры трейнинга (lr, epochs, batch, и т.д.) и **динамические блоки** для каждого узла: включение/выключение обучения, параметры регуляризации. Например, если добавлен ControlNet — блок «ControlNet: train on/off, scale, …». |
| 4 | **Blocks** | Каталог всех доступных блоков, разбитых по категориям (backbone, conditioner, adapter, solver, codec, segmenter, detector, и т.д.). Пользователь выбирает блок, добавляет в граф (вкладка Pipeline). |
| 5 | **Philosophy** | Документация, принципы архитектуры, ссылки на репозиторий и примеры. |

### 9A.2 Принцип работы

1. **Pipeline:** пользователь выбирает блоки из каталога (Blocks) и добавляет их в граф; выстраивает связи; нажимает **Materialize** — оркестратор собирает и материализует граф, пайплайн становится готовым к использованию.
2. **Inference / Train:** UI **полностью динамический**. По составу материализованного графа автоматически генерируются блоки параметров:
   - для каждого узла с входными портами (control_image, ip_image, conditioning_scale, и т.д.) — соответствующие виджеты;
   - в Inference: параметры для запуска генерации (prompt, steps, seed, guidance_scale, control_image, ip_image, …);
   - в Train: параметры обучения по узлам (train on/off для каждого адаптера, backbone, conditioner; lr, freeze/unfreeze).

3. **Пример:** пользователь добавил ControlNet в пайплайн и нажал Materialize. На вкладке **Inference** появляется блок «ControlNet» с полями: control_image (загрузка изображения), conditioning_scale. На вкладке **Train** появляется блок «ControlNet» с полями: train on/off, scale, и т.д. Аналогично для IP-Adapter, T2I-Adapter, backbone, conditioner — у каждого узла свои параметры, UI формируется **автоматически** по графу.

### 9A.3 Технические требования

- UI строится по **graph_inputs** и по **узлам графа** после материализации: для каждого порта — соответствующий виджет (text, number, image upload, checkbox, и т.д.).
- Связь с оркестратором: после Materialize граф и graph_inputs фиксированы; UI читает их и генерирует форму. При изменении графа (добавление/удаление узла) и повторной материализации — UI обновляется.
- Inference и Train используют **один и тот же граф**; различается только набор параметров (inference: входы для вызова; train: train on/off, lr, и т.д.) и действия при нажатии кнопки (generate vs train step/epoch).

---

## 10. Детализация, улучшения и элегантность решения

Ниже — уточнения структур данных, принципы, уменьшающие специальные случаи, и идеи, как сделать систему проще и предсказуемее. Эти пункты дополняют разделы 3–9 и должны учитываться при реализации to-do из раздела 11.

**Ключевые цели улучшений:** (1) один конвейер для всех ролей — без ветвлений по типу узла в ядре оркестратора; (2) идемпотентность и предсказуемость материализации; (3) явные контракты имён портов и форматов связей; (4) структурированная валидация и диагностика; (5) единая точка создания пайплайна и граф как единственный источник истины.

### 10.A Единый путь для всех узлов (no special cases)

**Принцип:** Любой узел (conditioner, backbone, adapter, codec, solver, segmenter, …) проходит **один и тот же конвейер**: REGISTER → RESOLVE → DEFER_OR_CONNECT. Различие только в данных реестра (роль → правила), а не в коде оркестратора.

- **Улучшение:** В коде не должно быть `if role == "adapter": ... elif role == "backbone": ...`. Вместо этого: `rule = registry.get_rule(role); target = resolver.resolve(rule, state); apply(rule, target, state)`.
- **Следствие:** Добавление новой роли = одна запись в реестре; ядро оркестратора не меняется.
- **Детализация:** RoleRegistry возвращает не «сырые» строки, а объект **NodeRule**: `target_hint` (имя узла или символ типа `DENOISE_LOOP`), `target_port`, `insert_into` (`"root"` | `"loop_inner"`), `graph_input_name` (если нужен проброс входа), `defer_if_missing` (список символов, при отсутствии которых отложить).

### 10.B Симметрия и обратимость

**Принцип:** Операции сборки по возможности симметричны и предсказуемы.

- **replace_node:** Уже есть; при замене узла внутри цикла (`loop.backbone`) оркестратор не пересоздаёт цикл — меняется только блок в узле. Валидация после замены — та же, что после add_node (фаза VALIDATE по запросу).
- **Улучшение:** Ввести явный `unregister_node(name)` или `remove_node(name)`: оркестратор откатывает связи (удаляет рёбра, при необходимости разбирает отложенные привязки). Тогда «добавить узел» и «удалить узел» — две стороны одного контракта графа.
- **Детализация:** При удалении узла, являющегося целевым для отложенных привязок, эти привязки возвращаются в очередь в состоянии «ожидание нового целевого узла» или аннулируются с предупреждением (политика задаётся в конфиге оркестратора).

### 10.C Идемпотентность материализации

**Принцип:** Повторный вызов `materialize()` после уже выполненной материализации не ломает граф и не дублирует узлы/рёбра.

- **Реализация:** В BuildState флаг `materialized: bool`. При первом вызове `materialize()` создаются циклы, обрабатывается очередь отложенных, флаг устанавливается в `True`. При последующих вызовах — no-op (или только обновление метаданных, если граф изменился через replace_node).
- **Улучшение:** Если после материализации был вызван `add_node` или `replace_node`, флаг сбрасывается в `False` (граф «грязный»); следующий `materialize()` или `to(device)` пересоберёт необходимое. Альтернатива: версионирование графа (version_id увеличивается при любом изменении); материализация кэшируется по паре (graph.version_id, state).

### 10.D Именование и контракты портов

**Единая схема имён:**

- **Входы графа:** `prompt`, `image`, `mask`, `latents`, `control_image`, `control_image_<node_name>`, `ip_image`, `ip_adapter_scale`, `num_inference_steps`, `guidance_scale`, и т.д. Опциональные входы адаптеров всегда с префиксом или суффиксом, позволяющим однозначно сопоставить узел: `control_image_<node_name>`.
- **Внутри шага цикла:** фиксированные имена портов `sample`, `timestep`, `condition`, `adapter_features`, `image_prompt_embeds`, `model_output`, `prev_sample` — общий контракт шага; конкретный backbone объявляет, какие из них использует.
- **Улучшение:** Документировать контракт в виде enum или констант (`PortNames.SAMPLE`, `PortNames.CONDITION`, …) и использовать их в шаблонах и реестрах, чтобы не было «магических строк» в коде.

### 10.E Формат связей (connections) для комбинированного пайплайна

**Детализация:** Единый способ задавать связи между этапами — список рёбер с явными портами.

- **Рекомендуемый формат:** `connections: List[Tuple[str, str, str, str]]` — `(src_stage, src_port, dst_stage, dst_port)`. Пример: `("stage1", "image", "stage2", "image")`.
- **Альтернатива для простого случая:** `default_link: Optional[Tuple[str, str]]` — пара (output_port, input_port) по умолчанию для линейной цепочки (например `("output", "input")`). Если `connections` пуст, применяется default_link между соседями по порядку ключей/списка.
- **Параллельные группы:** `parallel_groups: List[List[str]]` — список групп имён этапов; внутри группы этапы выполняются параллельно; между группами — по DAG. Объединение выходов группы задаётся отдельно: `merge_strategy: "dict" | "concat" | Callable` (по имени этапа → выход в словаре или конкатенация тензоров).

### 10.F Состояние оркестратора: неизменяемый снимок для валидации

**Улучшение:** BuildState разделить на две концепции:

- **Mutable state** (во время сборки): текущий граф, denoise_loop_node_name, deferred_adapter_bindings, metadata. Меняется при add_node, replace_node, materialize.
- **Snapshot для валидации:** после MATERIALIZE оркестратор строит **неизменяемый снимок** графа (топологический порядок, множество имён входов/выходов, список узлов цикла). Валидация работает только со снимком; это упрощает тесты и гарантирует, что валидация не зависит от последующих изменений графа до следующей материализации.

**Детализация:** Класс `GraphSnapshot` с полями `topological_order: List[str]`, `input_ports: Set[str]`, `output_ports: Set[str]`, `loop_node: Optional[str]`, `adapter_inputs: Dict[str, str]`. Метод `orchestrator.get_snapshot() -> Optional[GraphSnapshot]` возвращает снимок после материализации или `None`, если материализация ещё не выполнялась.

### 10.G Обработка ошибок и диагностика

- **Разрешение цели:** Если TargetResolver не может найти цель (например, adapter добавлен, но backbone так и не добавлен), не падать молча — при материализации выдавать **явную ошибку** с перечислением отложенных привязок, которые не удалось разрешить. Это упрощает отладку.
- **Валидация:** Возвращать не только «список строк», а структурированный результат: `ValidationResult(success: bool, errors: List[ValidationError], warnings: List[ValidationWarning])`, где каждый элемент содержит код, сообщение и контекст (имя узла, порт). Тогда UI или логи могут фильтровать по коду и показывать подсказки.
- **Улучшение:** В режиме разработки оркестратор может принимать `on_phase: Optional[Callable[[Phase, BuildState], None]]` — колбэк после каждой фазы для логирования или отладки без засорения основного кода.

### 10.H Элегантность API пайплайна

- **Единая точка входа для создания:** Один метод `InferencePipeline.from_spec(spec, **kwargs)`, где `spec` — либо один граф, либо список графов, либо словарь графов, либо путь к YAML/конфигу. Внутри — диспетчеризация по типу `spec`. Тогда пользователь не обязан помнить `from_graph` / `from_combined` / `from_config` — достаточно передать «что имею» в `from_spec`. Обратная совместимость: существующие методы остаются тонкими обёртками над `from_spec`.
- **Граф как источник истины:** Пайплайн не дублирует состояние графа. Все вопросы «какие входы/выходы», «сколько этапов» решаются обращением к `pipe.graph` (и к снимку, если есть). Это устраняет рассинхрон между графом и пайплайном.
- **Предсказуемый порядок выполнения:** Для комбинированного пайплайна порядок этапов однозначно определяется: (1) по connections строится DAG; (2) топологическая сортировка DAG; (3) внутри одной группы parallel_groups — параллельный запуск. Документировать это как гарантию.

### 10.I Что можно улучшить в перспективе

- **Ленивая материализация по подграфу:** Если граф очень большой, материализовать только «видимую» часть (например, этапы до текущего). Требует чёткого определения границ подграфа и усложняет модель.
- **Декларативное описание графа:** Описание графа в виде декларации (YAML/DSL) «узлы + роли», без императивных add_node; оркестратор строит граф из декларации за один проход. Уже частично есть в from_template / from_yaml; можно унифицировать и расширить.
- **Визуализация графа и снимка:** Вывод графа в формате для визуализации (Graphviz, Mermaid) из `GraphSnapshot` или из графа после материализации — помогает при отладке и в документации.
- **Типизация портов:** Порты не только по имени, но и по типу (Tensor, Image, Latents, Conditioning) — тогда валидация может проверять совместимость типов на рёбрах. Увеличивает сложность, но снижает ошибки конфигурации.

---

## 11. Детальный to-do по рефакторингу

### 11.1 Оркестратор

| # | Задача | Описание |
|---|--------|----------|
| O1 | Класс GraphBuildOrchestrator | Реализовать класс с состоянием (BuildState), фазами и методами register_node, materialize, validate, get_state, set_metadata. |
| O2 | RoleRegistry и NodeRule | Реестр: block_type/role → NodeRule (target_hint, target_port, insert_into, graph_input_name, defer_if_missing). Без ветвлений по роли в ядре оркестратора (см. разд. 10.A). |
| O3 | TargetResolver | Функция/класс resolve(rule: NodeRule, state) → (graph, node, port) или DEFER. Единый путь для всех ролей. |
| O4 | Очередь отложенных адаптеров | deferred_adapter_bindings; при материализации — вставка во inner graph цикла и проброс входов. |
| O5 | Интеграция с ComputeGraph | Вызов оркестратора из add_node (при auto_connect) и из to(device); без дублирования логики в pipeline_auto_wire и adapters. |
| O6 | GraphSnapshot и ValidationResult | После MATERIALIZE строить неизменяемый GraphSnapshot; validate() возвращать ValidationResult(errors, warnings) со структурированными кодами и контекстом (разд. 10.F, 10.G). |

### 11.2 Автосборка циклов

| # | Задача | Описание |
|---|--------|----------|
| L1 | Подмена backbone на LoopSubGraph | При добавлении backbone создавать узел-цикл с inner graph по шаблону шага. |
| L2 | Реестр LoopTemplates | По (solver_type, prediction_type, modality) возвращать step graph (scale_input → backbone → solver.step). |
| L3 | Generic step template | Универсальный шаблон для неизвестных пар backbone+solver; регистрация кастомных шаблонов. |
| L4 | Метаданные из графа | Извлечение latent_channels, use_euler_init_sigma, prediction_type из узлов и реестра; запись в metadata графа/цикла. |
| L5 | Связь с Diffusers | При импорте пайплайна из Diffusers определять тип scheduler и prediction_type, маппинг в шаблон шага. |

### 11.3 Адаптеры

| # | Задача | Описание |
|---|--------|----------|
| A1 | AdapterBindingRules | Реестр: adapter_type → (куда вставить, порт backbone, имя graph_input). Покрыть controlnet, ip_adapter, t2i_adapter, motion_adapter. |
| A2 | Имена control_image_* | Однозначные имена для нескольких ControlNet; маппинг control_type → input name при материализации. |
| A3 | Чистота опциональных входов | Перед run явно выставлять None для непереданных control_image*, ip_image; ip_adapter_scale только при переданном ip_image. |
| A4 | Расширение списка адаптеров | Сверить с актуальным Diffusers: все текущие и документированные адаптеры поддерживаются через регистрацию в AdapterBindingRules. |

### 11.4 Солверы и универсальность

| # | Задача | Описание |
|---|--------|----------|
| S1 | Реестр типов solver | Соответствие типу Diffusers scheduler → внутренний solver type и step signature. |
| S2 | Абстракция шага | Интерфейс шага (sample, timestep, condition, adapter_features, … → model_output / next_latents) для batched CFG, single-batch, flow, DiT. |
| S3 | cross_attention_dim из графа | Единственный источник для IP-Adapter и др. — конфиг модели в графе, без эвристик по имени. |
| S4 | Регистрация кастомных ролей и шаблонов | Плагин-механизм для world models и будущих архитектур без правки ядра. |

### 11.5 Недиффузионные пайплайны

| # | Задача | Описание |
|---|--------|----------|
| N1 | Роли segmenter, detector, classifier, depth_estimator, pose_estimator, super_resolution, style_encoder, processor | Правила подключения и опционально шаблоны графов. |
| N2 | Контракт входа/выхода | Словари с ключами image, mask, latents, audio, video; единый исполнитель. |
| N3 | Граф без цикла | Оркестратор не создаёт цикл; только соединение узлов по ролям. |

### 11.6 Обучение

| # | Задача | Описание |
|---|--------|----------|
| T1 | Режим training в графе и исполнителе | Флаг/контекст; отключение no_grad, сохранение градиентов. |
| T2 | train_nodes / freeze_nodes | Выбор обучаемых узлов по имени или маске (stage/node). |
| T3 | Loss-узлы и backward | Роль loss, порядок выполнения, backward от выхода loss. |
| T4 | Чекпоинты по узлам | Сохранение/загрузка только указанных узлов (например LoRA, adapter). |

### 11.7 Пайплайн (список/словарь графов)

| # | Задача | Описание |
|---|--------|----------|
| P1 | InferencePipeline(graphs=[...]) | Инициализация списком графов; последовательное выполнение; порядок по списку. |
| P2 | InferencePipeline(graphs={...}, connections=...) | Инициализация словарём; связи между этапами; по умолчанию — линейная цепочка. |
| P3 | Параллельные группы | parallel_groups и merge; план выполнения DAG с параллельными ветками. |
| P4 | Тот же API для одиночного и комбинированного | Один класс InferencePipeline / TrainingPipeline; без класса CombinedPipeline. Опционально: единая точка входа from_spec(spec) с диспетчеризацией по типу spec (разд. 10.H). |

### 11.8 Gradio-интерфейс

| # | Задача | Описание |
|---|--------|----------|
| G1 | 5 вкладок: Inference, Pipeline, Train, Blocks, Philosophy | Реализовать Gradio UI с указанными вкладками (разд. 9A). |
| G2 | Pipeline: сборка и кнопка Materialize | Вкладка Pipeline: выбор блоков из каталога (Blocks), добавление в граф, связи, кнопка Materialize — вызов оркестратора.materialize(). |
| G3 | Динамический Inference | По графу после материализации генерировать виджеты параметров для каждого graph_input (prompt, control_image, ip_image, conditioning_scale, и т.д.). |
| G4 | Динамический Train | По графу генерировать виджеты для каждого узла: train on/off, scale, lr и т.д. (адаптеры, backbone, conditioner). |
| G5 | Каталог Blocks по категориям | Вкладка Blocks: список блоков по категориям (backbone, conditioner, adapter, solver, codec, segmenter, detector, …); выбор → добавление в граф (Pipeline). |

### 11.9 Качество кода и практики

| # | Задача | Описание |
|---|--------|----------|
| Q1 | Устранение дублирования | Вся логика «куда подключить», «как построить цикл» — в оркестраторе и реестрах. |
| Q2 | Тесты | Юнит: добавление узлов по одному, проверка графа. Интеграция: pipe с/без control/ip, замена backbone, комбинированный из 2–3 этапов. Учёт идемпотентности materialize (разд. 10.C) и ValidationResult (10.G). |
| Q3 | Документация | Описание фаз оркестратора, таблицы ролей и адаптеров, примеры (диффузия, диффузия+адаптеры, недиффузионный, комбинированный). |
| Q4 | Обратная совместимость | Сохранить from_template, add_node(type="..."), pipe(prompt=..., control_image=..., ip_image=...); deprecation только с предупреждением. |

---

## 12. Порядок внедрения

1. **Фаза 1 — оркестратор и состояние:** GraphBuildOrchestrator, BuildState, фазы REGISTER → RESOLVE → DEFER_OR_CONNECT; интеграция с add_node и to(device).
2. **Фаза 2 — реестры:** RoleRegistry, TargetResolver, LoopTemplates (текущие шаблоны), AdapterBindingRules (controlnet, ip_adapter, t2i_adapter).
3. **Фаза 3 — отложенные адаптеры и чистота входов:** очередь deferred_adapter_bindings, материализация, явный None для опциональных входов, ip_adapter_scale только при ip_image.
4. **Фаза 4 — универсальные шаги и солверы:** абстракция шага, реестр по типу solver, маппинг из Diffusers; расширение LoopTemplates под все используемые в Diffusers типы.
5. **Фаза 5 — недиффузионные графы:** роли и правила для segmenter, detector, classifier, depth, pose, super_resolution, processor.
6. **Фаза 6 — обучение:** режим training, train_nodes/freeze_nodes, loss-узлы, backward, чекпоинты.
7. **Фаза 7 — пайплайн по списку/словарю:** InferencePipeline(graphs=[...]), InferencePipeline(graphs={...}, connections=...), parallel_groups.
8. **Фаза 8 — Gradio-интерфейс:** 5 вкладок (Inference, Pipeline, Train, Blocks, Philosophy), сборка → Materialize, динамические блоки параметров по графу.
9. **Фаза 9 — расширение адаптеров и примеры:** сверка с Diffusers (Motion Adapter и др.), пример многостадийного сценарного пайплайна, тесты и документация.

---

## 13. Критерии готовности

- Пользователь добавляет узлы (conditioner, несколько ControlNet, IP-Adapter, T2I-Adapter, backbone, codec) без ручных connect; граф собирается и выполняется корректно; адаптеры не «залипают».
- Любой зарегистрированный backbone + solver даёт корректный цикл денойзинга (в т.ч. при импорте из Diffusers); для неизвестной пары доступен generic или пользовательский шаблон.
- Все адаптеры из перечня Diffusers (ControlNet, IP-Adapter, T2I-Adapter, Motion Adapter и т.д.) реализуемы через регистрацию в AdapterBindingRules.
- InferencePipeline и TrainingPipeline принимают один граф, список графов или словарь графов; отдельного класса CombinedPipeline нет; комбинированный сценарий поддерживает последовательное и параллельное выполнение этапов.
- Обучение всего графа, подграфа или выбранных узлов работает с train_nodes/freeze_nodes и loss-узлами.
- Недиффузионные пайплайны (сегментация, детекция, классификация, глубина, супер-разрешение и т.д.) собираются и выполняются тем же оркестратором и исполнителем.
- Gradio-интерфейс: 5 вкладок (Inference, Pipeline, Train, Blocks, Philosophy); сборка в Pipeline → Materialize → динамические блоки параметров на Inference и Train по составу графа.
- Код соответствует заявленным лучшим практикам: единая точка принятия решений (оркестратор), расширяемость через реестры, тесты и документация.

---

---

## Приложение A. Эталонный перечень (Hugging Face Diffusers)

Источник актуальных списков: [diffusers — Pipelines](https://huggingface.co/docs/diffusers/main/en/api/pipelines/overview), [diffusers — Schedulers](https://huggingface.co/docs/diffusers/main/en/api/schedulers/overview), исходный код `src/diffusers/pipelines/` и `src/diffusers/schedulers/`.

### A.1 Семейства пайплайнов (ориентир для автосборки и шаблонов)

- **Image:** StableDiffusion, StableDiffusionXL, StableDiffusion3, ControlNet, Flux, Kandinsky 2.1/2.2/3, DeepFloyd IF, LatentConsistencyModel, DiT, Hunyuan-DiT, AuraFlow, BLIP-Diffusion, InstructPix2Pix, inpainting, image-to-image, super-resolution.
- **Video:** AnimateDiff, I2VGen-XL, CogVideoX, Text-to-Video, Image-to-Video.
- **Audio:** AudioLDM, AudioLDM2, MusicLDM, Dance Diffusion.
- **Другие:** depth-to-image, upscaling, интерполяция.

Движок должен позволять собирать граф, эквивалентный любому из этих пайплайнов (через шаблоны или импорт из Diffusers), и поддерживать кастомные архитектуры.

### A.2 Адаптеры (обязательный охват и расширение)

- ControlNet (все варианты: canny, depth, pose, segmentation, …).
- IP-Adapter (в т.ч. для SDXL, Flux, SD3).
- T2I-Adapter (depth, canny, sketch, и т.д.).
- Motion Adapter (AnimateDiff).
- LoRA / DoRA / Hypernetwork / Textual Inversion — как модификаторы весов или условий; LoRA подключается к backbone/transformer, остальные по контракту адаптера.

Любой новый адаптер из Diffusers или сообщества реализуем через блок + запись в AdapterBindingRules.

### A.3 Солверы (шелдулеры) — маппинг в Solver

- EulerDiscreteScheduler, EulerAncestralDiscreteScheduler.
- DDIMScheduler, DDIMInverseScheduler.
- DPMSolverMultistepScheduler, DPMSolverSinglestepScheduler.
- KDPM2DiscreteScheduler, KDPM2AncestralDiscreteScheduler.
- FlowMatchEulerDiscreteScheduler (SD3, Flux).
- LCMScheduler, UniPCMultistepScheduler, DEISMultistepScheduler.
- HeunDiscreteScheduler, LMSDiscreteScheduler.

В YggDrasil остаётся единое понятие Solver (расписание + step); конфиг и поведение согласованы с Diffusers через копирование конфига или маппинг при импорте.

---

*Документ можно использовать как техническое задание и пошаговый план рефакторинга движка графовых пайплайнов YggDrasil с опорой на Hugging Face Diffusers и требования к универсальности и надёжности.*
