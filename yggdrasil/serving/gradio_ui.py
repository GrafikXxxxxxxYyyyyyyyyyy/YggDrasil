# yggdrasil/serving/gradio_ui.py
"""Gradio UI –¥–ª—è YggDrasil ‚Äî –µ–¥–∏–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –ª—é–±—ã—Ö –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π (image, video, audio).

–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
- –í—ã–±–æ—Ä –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–∏ (–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ / –í–∏–¥–µ–æ / –ê—É–¥–∏–æ) –∏ —à–∞–±–ª–æ–Ω–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞
- –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –≤—Ö–æ–¥—ã –ø–æ –≥—Ä–∞—Ñ—É (prompt, control_image, num_frames –∏ —Ç.–¥.)
- –ü—Ä–µ—Å–µ—Ç—ã —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–π –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, —Å–µ–º—è, –±–∞—Ç—á, —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
- –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ –∏ –ø–æ–Ω—è—Ç–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –æ–± –æ—à–∏–±–∫–∞—Ö
"""
from __future__ import annotations

import io
import time
import random
import torch
import numpy as np
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple
from PIL import Image

from .schema import ServerConfig


# ==================== HELPERS ====================

def _get_device_info() -> str:
    if torch.cuda.is_available():
        name = torch.cuda.get_device_name(0)
        props = torch.cuda.get_device_properties(0)
        mem = getattr(props, "total_memory", getattr(props, "total_mem", 0)) / 1e9
        return f"CUDA: {name} ({mem:.1f} GB)"
    if getattr(torch.backends, "mps", None) and torch.backends.mps.is_available():
        return "Apple MPS"
    return "CPU"


def _best_device() -> str:
    if torch.cuda.is_available():
        return "cuda"
    if getattr(torch.backends, "mps", None) and torch.backends.mps.is_available():
        return "mps"
    return "cpu"


def _tensor_to_pil_list(tensor: torch.Tensor) -> List[Image.Image]:
    """–¢–µ–Ω–∑–æ—Ä [B, C, H, W] –≤ [-1,1] –∏–ª–∏ [0,1] ‚Üí —Å–ø–∏—Å–æ–∫ PIL."""
    if tensor is None or not isinstance(tensor, torch.Tensor):
        return []
    img = tensor.detach().cpu().float()
    if img.min() < -0.01 or img.max() > 1.01:
        img = (img / 2 + 0.5).clamp(0, 1)
    else:
        img = img.clamp(0, 1)
    images = []
    for i in range(img.shape[0]):
        arr = (img[i].permute(1, 2, 0).numpy() * 255).clip(0, 255).astype(np.uint8)
        if arr.shape[-1] == 1:
            arr = arr.squeeze(-1)
        images.append(Image.fromarray(arr))
    return images


def _video_tensor_to_file(tensor: torch.Tensor, fps: float = 8.0) -> Optional[str]:
    """–¢–µ–Ω–∑–æ—Ä –≤–∏–¥–µ–æ [B,C,T,H,W] –∏–ª–∏ [C,T,H,W] ‚Üí –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª .mp4."""
    if tensor is None or not isinstance(tensor, torch.Tensor):
        return None
    try:
        import tempfile
        t = tensor.detach().cpu().float()
        if t.min() < -0.01 or t.max() > 1.01:
            t = (t / 2 + 0.5).clamp(0, 1)
        if t.dim() == 5:
            t = t[0]
        # [C, T, H, W] ‚Üí frames (T, H, W, C)
        t = t.permute(1, 2, 3, 0).numpy()
        t = (t * 255).clip(0, 255).astype(np.uint8)
        path = tempfile.mktemp(suffix=".mp4")
        try:
            import imageio
            imageio.mimwrite(path, t, fps=fps)
            return path
        except ImportError:
            return None
    except Exception:
        return None


def _audio_tensor_to_file(tensor: torch.Tensor, sr: int = 44100) -> Optional[Tuple[int, np.ndarray]]:
    """–¢–µ–Ω–∑–æ—Ä –∞—É–¥–∏–æ [B, C, T] –∏–ª–∏ [C, T] ‚Üí (sample_rate, np.ndarray)."""
    if tensor is None or not isinstance(tensor, torch.Tensor):
        return None
    try:
        a = tensor.detach().cpu().float().numpy()
        if a.ndim == 3:
            a = a[0]
        if a.ndim == 2:
            a = a.mean(axis=0)
        a = np.clip(a, -1, 1).astype(np.float32)
        return (sr, a)
    except Exception:
        return None


def _get_templates_by_modality() -> Dict[str, List[Tuple[str, str]]]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç {modality: [(template_id, description), ...]}."""
    try:
        from yggdrasil.pipeline import Pipeline
        available = Pipeline.list_available()
    except Exception:
        available = {}
    result = {"image": [], "video": [], "audio": []}
    for name, info in available.items():
        desc = (info.get("description") or name).strip().split("\n")[0][:80]
        mod = info.get("modality", "image")
        if mod not in result:
            result[mod] = []
        result[mod].append((name, desc))
    for mod in result:
        result[mod].sort(key=lambda x: x[0])
    if not any(result.values()):
        result["image"] = [("sd15_txt2img", "SD 1.5 Text-to-Image")]
    return result


# ==================== MAIN UI ====================

def create_ui(
    manager: Optional[Any] = None,
    config: Optional[ServerConfig] = None,
    share: bool = False,
) -> "gr.Blocks":
    """–°–æ–∑–¥–∞—Ç—å –µ–¥–∏–Ω—ã–π Gradio –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –ª—é–±—ã—Ö –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π."""
    import gradio as gr

    templates_by_mod = _get_templates_by_modality()
    device = _best_device()
    device_info = _get_device_info()

    # ---------- Generation logic ----------
    def run_generation(
        modality: str,
        template_name: str,
        prompt: str,
        negative_prompt: str,
        num_steps: int,
        guidance_scale: float,
        width: int,
        height: int,
        num_frames: int,
        seed: int,
        batch_size: int,
        control_image: Optional[Any],
        ip_image: Optional[Any],
        source_image: Optional[Any],
        pipeline_state: Optional[Tuple[str, Any]],
    ) -> Tuple[
        Optional[List[Image.Image]],
        Optional[str],
        Optional[Tuple[int, np.ndarray]],
        str,
        Optional[Tuple[str, Any]],
    ]:
        """–ó–∞–ø—É—Å–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (images, video_path, audio_tuple, info, new_pipeline_state)."""
        if not template_name or template_name not in [t[0] for t in templates_by_mod.get(modality, [])]:
            return [], None, None, "–í—ã–±–µ—Ä–∏—Ç–µ —à–∞–±–ª–æ–Ω –ø–∞–π–ø–ª–∞–π–Ω–∞.", pipeline_state

        try:
            from yggdrasil.pipeline import Pipeline
        except ImportError as e:
            return [], None, None, f"–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}", pipeline_state

        # Reuse pipeline if same template
        pipe = None
        if pipeline_state and pipeline_state[0] == template_name:
            pipe = pipeline_state[1]
        if pipe is None:
            try:
                pipe = Pipeline.from_template(template_name, device=device)
            except Exception as e:
                return [], None, None, f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–∞–π–ø–ª–∞–π–Ω: {e}", pipeline_state
            pipeline_state = (template_name, pipe)

        def _pil_to_tensor(pil_img) -> torch.Tensor:
            if pil_img is None:
                return None
            if isinstance(pil_img, dict) and "image" in pil_img:
                pil_img = pil_img["image"]
            arr = np.array(pil_img).astype(np.float32) / 255.0
            if arr.ndim == 2:
                arr = np.stack([arr] * 3, axis=-1)
            t = torch.from_numpy(arr).permute(2, 0, 1).unsqueeze(0)
            return t

        actual_seed = int(seed) if seed >= 0 else random.randint(0, 2**32 - 1)
        kwargs = {
            "prompt": prompt or "a beautiful scene",
            "negative_prompt": negative_prompt or "",
            "num_steps": num_steps,
            "guidance_scale": guidance_scale,
            "width": width,
            "height": height,
            "seed": actual_seed,
            "batch_size": min(max(1, batch_size), 8),
        }
        if modality == "video":
            kwargs["num_frames"] = num_frames
        if control_image is not None:
            kwargs["control_image"] = _pil_to_tensor(control_image)
        if ip_image is not None:
            kwargs["ip_image"] = ip_image if isinstance(ip_image, dict) else {"image": ip_image}
        if source_image is not None and modality in ("video", "image"):
            kwargs["source_image"] = _pil_to_tensor(source_image)

        start = time.time()
        try:
            out = pipe(**kwargs)
        except Exception as e:
            return [], None, None, f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}", pipeline_state
        elapsed = time.time() - start

        images = None
        video_path = None
        audio_data = None
        if out.images:
            images = out.images
        if getattr(out, "video", None) is not None:
            video_path = _video_tensor_to_file(out.video)
        if getattr(out, "audio", None) is not None:
            audio_data = _audio_tensor_to_file(out.audio)

        info = f"Seed: {actual_seed} | Steps: {num_steps} | CFG: {guidance_scale} | {elapsed:.1f}s | {device_info}"
        return images or [], video_path, audio_data, info, pipeline_state

    def update_template_choices(modality: str):
        choices = templates_by_mod.get(modality, [])
        return gr.update(choices=[t[0] for t in choices], value=choices[0][0] if choices else None)

    # ---------- Build UI ----------
    with gr.Blocks(
        title="YggDrasil ‚Äî Universal Diffusion",
        theme=gr.themes.Soft(
            primary_hue="indigo",
            secondary_hue="slate",
        ),
        css="""
        .hero { text-align: center; margin-bottom: 0.5em; font-size: 1.8em; }
        .sub { text-align: center; color: #64748b; margin-bottom: 1.2em; }
        .preset-btn { min-width: 4em; }
        .footer { text-align: center; margin-top: 1.5em; color: #94a3b8; font-size: 0.9em; }
        """,
    ) as demo:

        gr.HTML('<h1 class="hero">üå≥ YggDrasil</h1><p class="sub">–ï–¥–∏–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –≤–∏–¥–µ–æ –∏ –∑–≤—É–∫–∞</p>')

        pipeline_state = gr.State(value=None)

        with gr.Tabs():
            # ========== TAB: GENERATE ==========
            with gr.Tab("üé® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è", id="gen"):
                with gr.Row():
                    with gr.Column(scale=1):
                        gr.Markdown("### –ú–æ–¥–µ–ª—å –∏ –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç—å")
                        modality_radio = gr.Radio(
                            choices=[("–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", "image"), ("–í–∏–¥–µ–æ", "video"), ("–ê—É–¥–∏–æ", "audio")],
                            value="image",
                            label="–¢–∏–ø",
                            elem_id="modality",
                        )
                        template_dropdown = gr.Dropdown(
                            label="–ü–∞–π–ø–ª–∞–π–Ω",
                            choices=[t[0] for t in templates_by_mod["image"]],
                            value=templates_by_mod["image"][0][0] if templates_by_mod["image"] else None,
                            interactive=True,
                        )
                        num_frames_num = gr.Slider(4, 64, value=16, step=1, label="–ö–∞–¥—Ä–æ–≤ (–≤–∏–¥–µ–æ)", visible=False)
                        def on_modality(m):
                            choices = templates_by_mod.get(m, [])
                            vis = m == "video"
                            return (
                                gr.update(choices=[t[0] for t in choices], value=choices[0][0] if choices else None),
                                gr.update(visible=vis),
                            )
                        modality_radio.change(
                            fn=on_modality,
                            inputs=[modality_radio],
                            outputs=[template_dropdown, num_frames_num],
                        )

                        gr.Markdown("### –¢–µ–∫—Å—Ç –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã")
                        prompt_input = gr.Textbox(
                            label="Prompt",
                            placeholder="–æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≥–æ, —á—Ç–æ –≤—ã —Ö–æ—Ç–∏—Ç–µ –ø–æ–ª—É—á–∏—Ç—å...",
                            lines=3,
                        )
                        negative_input = gr.Textbox(
                            label="Negative Prompt",
                            placeholder="—Ä–∞–∑–º—ã—Ç–æ, –Ω–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ...",
                            lines=2,
                        )
                        with gr.Row():
                            steps_num = gr.Slider(1, 150, value=28, step=1, label="–®–∞–≥–∏")
                            cfg_num = gr.Slider(0.5, 30, value=7.5, step=0.5, label="CFG")
                        with gr.Row():
                            width_num = gr.Slider(128, 2048, value=512, step=64, label="–®–∏—Ä–∏–Ω–∞")
                            height_num = gr.Slider(128, 2048, value=512, step=64, label="–í—ã—Å–æ—Ç–∞")
                        with gr.Row():
                            seed_num = gr.Number(label="Seed (-1 = —Å–ª—É—á–∞–π–Ω—ã–π)", value=-1, precision=0)
                            seed_random_btn = gr.Button("üé≤ –°–ª—É—á–∞–π–Ω—ã–π", size="sm")
                            batch_num = gr.Slider(1, 8, value=1, step=1, label="–ë–∞—Ç—á")
                        seed_random_btn.click(lambda: -1, outputs=[seed_num])

                        gr.Markdown("#### –ü—Ä–µ—Å–µ—Ç—ã")
                        with gr.Row():
                            gr.Button("512√ó512").click(lambda: (512, 512), outputs=[width_num, height_num])
                            gr.Button("768√ó768").click(lambda: (768, 768), outputs=[width_num, height_num])
                            gr.Button("1024√ó1024").click(lambda: (1024, 1024), outputs=[width_num, height_num])
                            gr.Button("–ë—ã—Å—Ç—Ä–æ (20 —à–∞–≥–æ–≤)").click(lambda: 20, outputs=[steps_num])
                            gr.Button("–ö–∞—á–µ—Å—Ç–≤–æ (40 —à–∞–≥–æ–≤)").click(lambda: 40, outputs=[steps_num])
                        gr.Markdown("#### –ê–¥–∞–ø—Ç–µ—Ä—ã (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)")
                        control_image_in = gr.Image(label="Control (depth/canny)", type="pil")
                        ip_image_in = gr.Image(label="IP-Adapter –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", type="pil")
                        source_image_in = gr.Image(label="–ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (img2vid)", type="pil")

                        gen_btn = gr.Button("üöÄ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å", variant="primary", size="lg")

                    with gr.Column(scale=2):
                        gr.Markdown("### –†–µ–∑—É–ª—å—Ç–∞—Ç")
                        out_gallery = gr.Gallery(
                            label="–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è",
                            columns=3,
                            height=500,
                            object_fit="contain",
                        )
                        out_video = gr.Video(label="–í–∏–¥–µ–æ", visible=False)
                        out_audio = gr.Audio(label="–ê—É–¥–∏–æ", visible=False)
                        gen_info = gr.Textbox(label="–ò–Ω—Ñ–æ", interactive=False)
                        download_btn = gr.DownloadButton(label="–°–∫–∞—á–∞—Ç—å –ø–µ—Ä–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç", visible=True)

                def run_and_show(
                    mod, tpl, prompt, neg, steps, cfg, w, h, nf, seed, batch,
                    ctrl_img, ip_img, src_img, state,
                ):
                    images, video_path, audio_data, info, new_state = run_generation(
                        mod, tpl, prompt, neg, steps, cfg, w, h, nf, seed, batch,
                        ctrl_img, ip_img, src_img, state,
                    )
                    vis_img = bool(images and len(images) > 0)
                    vis_vid = video_path is not None
                    vis_aud = audio_data is not None
                    # Download: first image as bytes or video path
                    download_file = None
                    if images and len(images) > 0:
                        buf = io.BytesIO()
                        images[0].save(buf, format="PNG")
                        buf.seek(0)
                        download_file = (buf.getvalue(), "yggdrasil_output.png")
                    elif video_path:
                        download_file = video_path
                    return (
                        gr.update(value=images or [], visible=vis_img),
                        gr.update(value=video_path, visible=vis_vid),
                        gr.update(value=audio_data, visible=vis_aud),
                        info,
                        new_state,
                        download_file,
                    )

                gen_btn.click(
                    fn=run_and_show,
                    inputs=[
                        modality_radio, template_dropdown,
                        prompt_input, negative_input,
                        steps_num, cfg_num, width_num, height_num, num_frames_num,
                        seed_num, batch_num,
                        control_image_in, ip_image_in, source_image_in,
                        pipeline_state,
                    ],
                    outputs=[
                        out_gallery,
                        out_video,
                        out_audio,
                        gen_info,
                        pipeline_state,
                        download_btn,
                    ],
                )

            # ========== TAB: PIPELINES ==========
            with gr.Tab("üì¶ –ü–∞–π–ø–ª–∞–π–Ω—ã", id="pipelines"):
                gr.Markdown("### –î–æ—Å—Ç—É–ø–Ω—ã–µ —à–∞–±–ª–æ–Ω—ã –ø–æ —Ç–∏–ø—É")
                with gr.Row():
                    with gr.Column():
                        gr.Markdown("#### –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
                        img_list = "\n".join(f"- **{t[0]}** ‚Äî {t[1]}" for t in templates_by_mod.get("image", [])[:20])
                        gr.Markdown(img_list or "–ù–µ—Ç —à–∞–±–ª–æ–Ω–æ–≤")
                    with gr.Column():
                        gr.Markdown("#### –í–∏–¥–µ–æ")
                        vid_list = "\n".join(f"- **{t[0]}** ‚Äî {t[1]}" for t in templates_by_mod.get("video", [])[:20])
                        gr.Markdown(vid_list or "–ù–µ—Ç —à–∞–±–ª–æ–Ω–æ–≤")
                    with gr.Column():
                        gr.Markdown("#### –ê—É–¥–∏–æ")
                        aud_list = "\n".join(f"- **{t[0]}** ‚Äî {t[1]}" for t in templates_by_mod.get("audio", [])[:20])
                        gr.Markdown(aud_list or "–ù–µ—Ç —à–∞–±–ª–æ–Ω–æ–≤")
                gr.Markdown("–í—ã–±–µ—Ä–∏—Ç–µ —à–∞–±–ª–æ–Ω –≤–æ –≤–∫–ª–∞–¥–∫–µ **–ì–µ–Ω–µ—Ä–∞—Ü–∏—è** –∏ –Ω–∞–∂–º–∏—Ç–µ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å. –ú–æ–¥–µ–ª–∏ –ø–æ–¥–≥—Ä—É–∂–∞—é—Ç—Å—è –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ.")

            # ========== TAB: BLOCKS ==========
            with gr.Tab("üß± –ë–ª–æ–∫–∏", id="blocks"):
                gr.Markdown("### –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –±–ª–æ–∫–∏ (Lego)")
                def get_blocks_md():
                    try:
                        from yggdrasil.core.block.registry import list_blocks
                        blocks = list_blocks()
                        if not blocks:
                            return "–ù–µ—Ç –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –±–ª–æ–∫–æ–≤."
                        by_cat = {}
                        for k, cls in sorted(blocks.items()):
                            cat = k.split("/")[0] if "/" in k else "other"
                            by_cat.setdefault(cat, []).append((k, cls))
                        lines = []
                        for cat, items in sorted(by_cat.items()):
                            lines.append(f"\n### {cat.upper()}")
                            for k, cls in items:
                                doc = (cls.__doc__ or "").split("\n")[0].strip()[:70]
                                lines.append(f"- `{k}` ‚Äî {doc}")
                        return "\n".join(lines)
                    except Exception as e:
                        return f"–û—à–∏–±–∫–∞: {e}"
                blocks_md = gr.Markdown(value=get_blocks_md())
                gr.Button("–û–±–Ω–æ–≤–∏—Ç—å").click(fn=get_blocks_md, outputs=[blocks_md])

            # ========== TAB: TRAIN ==========
            with gr.Tab("üéì –û–±—É—á–µ–Ω–∏–µ", id="train"):
                gr.Markdown("### –û–±—É—á–µ–Ω–∏–µ –∞–¥–∞–ø—Ç–µ—Ä–∞ / –¥–æ–æ–±—É—á–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞")
                with gr.Row():
                    with gr.Column():
                        train_template = gr.Dropdown(
                            label="–®–∞–±–ª–æ–Ω –≥—Ä–∞—Ñ–∞",
                            choices=[t[0] for t in (templates_by_mod["image"] + templates_by_mod.get("video", []) + templates_by_mod.get("audio", []))],
                            value=templates_by_mod["image"][0][0] if templates_by_mod["image"] else None,
                        )
                        train_nodes = gr.Textbox(label="–û–±—É—á–∞–µ–º—ã–µ —É–∑–ª—ã (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)", value="lora_adapter", placeholder="backbone, lora_adapter")
                        train_data = gr.Textbox(label="–ü—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º", placeholder="/path/to/images/")
                        train_epochs = gr.Slider(1, 500, value=10, step=1, label="–≠–ø–æ—Ö–∏")
                        train_lr = gr.Number(label="Learning rate", value=1e-4)
                    with gr.Column():
                        train_btn = gr.Button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ", variant="primary")
                        train_status = gr.Textbox(label="–°—Ç–∞—Ç—É—Å", interactive=False, lines=5)
                def start_train(tpl, nodes, data, epochs, lr):
                    if not data or not Path(data).exists():
                        return f"–ü—É—Ç—å –Ω–µ –Ω–∞–π–¥–µ–Ω: {data}"
                    try:
                        from yggdrasil.core.graph.graph import ComputeGraph
                        from yggdrasil.training.graph_trainer import GraphTrainer, GraphTrainingConfig
                        from yggdrasil.training.data import ImageFolderSource
                        g = ComputeGraph.from_template(tpl)
                        nlist = [n.strip() for n in nodes.split(",") if n.strip()]
                        cfg = GraphTrainingConfig(num_epochs=int(epochs), batch_size=1, learning_rate=float(lr))
                        trainer = GraphTrainer(graph=g, train_nodes=nlist, config=cfg)
                        ds = ImageFolderSource(data)
                        import threading
                        def run():
                            try:
                                trainer.train(ds)
                            except Exception as e:
                                print(f"Train error: {e}")
                        threading.Thread(target=run, daemon=True).start()
                        return f"–û–±—É—á–µ–Ω–∏–µ –∑–∞–ø—É—â–µ–Ω–æ: {tpl}, —É–∑–ª—ã {nlist}, —ç–ø–æ—Ö {epochs}"
                    except Exception as e:
                        return f"–û—à–∏–±–∫–∞: {e}"
                train_btn.click(
                    fn=start_train,
                    inputs=[train_template, train_nodes, train_data, train_epochs, train_lr],
                    outputs=[train_status],
                )

        gr.HTML(f'<div class="footer">YggDrasil ‚Äî Lego –¥–ª—è –¥–∏—Ñ—Ñ—É–∑–∏–∏ ¬∑ {device_info}</div>')

    return demo
