# Механизм LoRA-адаптеров мира и лёгкие кастомные миры

**Цель:** реализовать механизм, при котором **все веса собранного мира замораживаются**, а ко **всем необходимым частям** подключаются **LoRA-адаптеры** (или аналогичные обучаемые адаптеры), которые **можно обучать**. В результате получаются **лёгкие кастомные миры**: один базовый мир (замороженный) + небольшие обучаемые адаптеры под конкретный сценарий или стиль.

Связь с каноном: [Scheme.md](Scheme.md), [World_Level.md](World_Level.md). Обучаемость: [TRAINABILITY_AT_ALL_LEVELS.md](TRAINABILITY_AT_ALL_LEVELS.md).

---

## 1. Идея

- **Базовый мир** собирается из блоков (графы, пайплайны, этапы: Философ, Автор, Среда, Архитектор, Творец). Все веса этого мира считаются **базовыми** и при включении механизма **замораживаются**.
- **LoRA (и аналоги)** подключаются ко **всем необходимым частям** мира: к каждому backbone, к каждому LLM/кондиционеру, к любым блокам с обучаемыми параметрами, где это имеет смысл. Адаптер инжектируется в блок по единому контракту (например, линейные слои, внимание).
- **Обучаются только адаптеры.** Базовые веса не обновляются. В итоге кастомный мир = базовый мир (один раз загружен, заморожен) + набор весов LoRA (небольшой объём), что даёт **лёгкие кастомные миры** без полного fine-tune всего мира.

---

## 2. Требования к механизму

| Требование | Описание |
|------------|----------|
| **Создание LoRA-адаптеров «на весь мир»** | Механизм должен позволять автоматически или по конфигу **создать и подключить LoRA-адаптеры ко всем нужным блокам** в мире (по графу этапов → пайплайнам → графам → узлам-блокам). Не только к одному backbone, а ко всем backbone’ам, LLM, conditioner’ам и т.д., где предусмотрена поддержка адаптеров. |
| **Обучение отдельных «нейронов» как LoRA** | Возможность обучать **отдельные параметры** (или малые подмножества) в виде адаптеров: не только классическая LoRA (low-rank), но и, при необходимости, другие варианты (адаптеры по слоям, по модулям). Суть: **все базовые веса заморожены**, обучается только лёгкий адаптер. |
| **Заморозка всех весов базового мира** | При активации режима «лёгкий кастомный мир» **все веса**, входящие в собранный мир (все блоки на всех уровнях), **замораживаются**. Обучаемые параметры — только добавленные LoRA/адаптеры. |
| **Подключение LoRA ко всем необходимым частям** | Конфиг или автоматика задаёт, к каким блокам (типам блоков, конкретным узлам) подключать адаптеры. «Все необходимые части» = все блоки мира, имеющие обучаемые параметры и поддержку инжекции адаптера (backbone, conditioner, LLM в Авторе/Архитекторе/Development и т.д.). |

Итого: механизм **создания LoRA-адаптеров на весь мир**, **заморозки всех весов** базового мира и **обучения только адаптеров** для получения **лёгких кастомных миров**.

---

## 3. Лёгкие кастомные миры

**Лёгкий кастомный мир** — это:

- **Базовый мир** (полная структура: этапы, пайплайны, графы, блоки) с **замороженными** весами.
- **Набор весов LoRA** (и/или других адаптеров), по одному или несколько на блок, где это предусмотрено.
- Обучение только этих адаптеров под задачу (стиль, домен, сценарий); сохранение и распространение — только малый объём (адаптеры), без дублирования базового мира.

Пользователь может иметь **один базовый мир** и много **вариантов кастомных миров** за счёт разных наборов LoRA, что масштабируемо и экономно по памяти и вычислениям.

---

## 4. Следствия для реализации

- **Обход мира по уровням:** от мира (граф этапов) вниз по этапам → пайплайны → графы → узлы (блоки). Для каждого блока с обучаемыми параметрами и с поддержкой адаптеров: создать экземпляр LoRA (или аналога), инжектировать в блок, заморозить базовые параметры блока, в оптимизатор передать только параметры адаптеров.
- **Единый контракт инжекции:** блоки, поддерживающие LoRA (backbone, conditioner, LLM и т.д.), объявляют слот или интерфейс для адаптера; механизм «LoRA для всего мира» подключает адаптер ко всем таким блокам по этому контракту.
- **Конфиг:** включение режима «лёгкий кастомный мир» (freeze all, add LoRA to all eligible blocks), ранг LoRA, список типов блоков или конкретных узлов для адаптеров; сериализация мира тогда сохраняет базовый конфиг мира + конфиг и веса адаптеров (лёгкий чекпоинт).

Итого: необходимо реализовать **механизм создания LoRA-адаптеров на весь мир**, **заморозки всех весов** базового мира и **обучения только этих адаптеров**, чтобы поддерживать **лёгкие кастомные миры**.
