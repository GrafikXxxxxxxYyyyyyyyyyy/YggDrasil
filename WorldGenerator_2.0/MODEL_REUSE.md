# Повторное использование одной и той же модели (без дублирования в памяти)

**Требование:** в фреймворке должен быть **механизм повторного использования одной и той же модели** (одного и того же чекпоинта), когда несколько узлов или графов используют **абсолютно одинаковые** веса. Модель не создаётся в нескольких копиях и не загружается в память повторно — используется один экземпляр, чтобы **не тратить лишнюю память**.

Канон: [SERIALIZATION_AT_ALL_LEVELS.md](SERIALIZATION_AT_ALL_LEVELS.md), [Pipeline_Level.md](Pipeline_Level.md), [Graph_Level.md](Graph_Level.md), [Abstract_Task_Nodes.md](Abstract_Task_Nodes.md).

---

## 1. Принцип (парадигма)

**Все модели, используемые во фреймворке, подчиняются одному правилу:** если где-либо встречается **дублирующаяся модель** — одна и та же, полностью идентичная (тот же чекпоинт, та же конфигурация загрузки) — то не важно, это backbone, solver, codec, conditioner, tokenizer, adapter, guidance, LLM, VLM или любой другой блок: она **инициализируется в памяти один раз** и **переиспользуется во всех местах**, где на неё ссылаются. Никакого лишнего потребления памяти: **абсолютно идентичные модели инициализируются один раз и переиспользуются всеми процессами/узлами/графами/пайплайнами/этапами независимо от уровня иерархии** (граф, пайплайн, этап, мир). Один идентификатор (checkpoint_ref / model_id) → один экземпляр в памяти; все потребители используют этот экземпляр.

---

## 2. Цель

- **Экономия памяти:** если в пайплайне (или на уровне графа, этапа, мира) две или более задач используют один и тот же чекпоинт модели — например, text-to-image и image-to-image с одним и тем же диффузионным бэкбоном, или несколько узлов с одной и той же LLM — то в памяти должна находиться **одна загруженная модель**, а не несколько копий.
- **Все типы моделей без исключения:** механизм распространяется на **все типы моделей** — backbone, solver, codec, conditioner, tokenizer, adapter, guidance, LLM, VLM и любые другие блоки с весами или с доступом по API. Нет исключений: полностью идентичная модель (любого типа) инициализируется один раз и переиспользуется.
- **Все уровни иерархии:** одно и то же правило действует **независимо от уровня** — внутри одного графа (несколько узлов с одним чекпоинтом), между графами в пайплайне, между пайплайнами в этапе, между этапами в мире. Где бы ни использовалась одна и та же модель, в памяти один экземпляр, остальные места получают ссылку на него.
- **Идентификация «одна и та же модель»:** критерий — совпадение **идентификатора чекпоинта** (путь, URI, ref в конфиге) и при необходимости конфигурации загрузки. Конфиг может указывать `checkpoint_ref: "shared/backbone.pt"` или аналог; реестр/пул при сборке возвращают один и тот же экземпляр блока для одного и того же ref.

---

## 3. Примеры сценариев

### 3.1 Пайплайн: text-to-image и image-to-image с одним чекпоинтом

- В пайплайне два графа: **G1** (text-to-image) и **G2** (image-to-image). Оба используют один и тот же диффузионный backbone (один и тот же чекпоинт, одна и та же архитектура).
- **Без механизма повторного использования:** при загрузке пайплайна в память загружаются две копии backbone → двойной расход памяти.
- **С механизмом:** при сборке пайплайна (или графов) фреймворк распознаёт, что G1 и G2 запрашивают один и тот же чекпоинт (и конфиг) backbone; создаётся **один экземпляр** блока backbone, который передаётся или переиспользуется в обоих графах (например, оба графа ссылаются на один и тот же объект блока, либо графы получают блок из общего пула по checkpoint_ref). При run оба графа используют одну и ту же модель.

### 3.2 Один и тот же LLM в нескольких узлах графа или этапа

- В графе или в разных пайплайнах этапа один и тот же LLM (один и тот же чекпоинт или один и тот же API model_id).
- **Требование:** один загруженный экземпляр (или один клиент API) на один checkpoint_ref / model_id; вызовы run обращаются к одному экземпляру, без дублирования весов в памяти.

### 3.3 Общий кодек или conditioner в нескольких графах пайплайна

- Несколько графов в пайплайне используют один и тот же VAE (кодек) или один и тот же текстный энкодер (conditioner).
- **Требование:** одна загрузка весов, один экземпляр блока; повторное использование по идентификатору чекпоинта/ref.

---

## 4. Требования к реализации

- [ ] **Идентификатор повторного использования:** в конфиге блока/узла или графа задаётся способ однозначно идентифицировать «ту же самую модель»: например, `checkpoint_path`, `checkpoint_ref`, `model_id` (для API) или хэш конфига загрузки. Узлы/графы с одинаковым идентификатором при сборке получают доступ к **одному экземпляру** модели (или к одному клиенту API).
- [ ] **Пул / реестр экземпляров:** глобально или на уровне сборки (граф, пайплайн, этап, мир) — пул (кэш) «checkpoint_ref → экземпляр блока». При добавлении узла или графа с уже известным ref блок не создаётся заново и не загружается повторно; возвращается ссылка на существующий экземпляр. **Независимо от уровня иерархии:** один и тот же ref в любом графе, пайплайне, этапе или мире даёт один и тот же экземпляр. Потокобезопасность и жизненный цикл задаются политикой фреймворка.
- [ ] **Совместимость с сериализацией:** при сохранении графа/пайплайна конфиг по-прежнему хранит ref на чекпоинт (или путь); при загрузке из чекпоинта механизм повторного использования применяется снова (узлы с одним ref снова разделяют один экземпляр). Сериализация не дублирует веса по числу использований; веса хранятся один раз, а в структуре графа/пайплайна указываются ссылки на общий блок или ref. Связь с [SERIALIZATION_AT_ALL_LEVELS.md](SERIALIZATION_AT_ALL_LEVELS.md).
- [ ] **Документация:** как в конфиге указать общий чекпоинт для нескольких узлов/графов; как работает пул/кэш; как отключить повторное использование (если нужно явно две копии) для специальных сценариев. Подробные сценарии обучения при повторном использовании (коллизии, решения, обходы): [TRAINING_REUSE_AND_API_SCENARIOS.md](TRAINING_REUSE_AND_API_SCENARIOS.md).

---

## 5. Критерии приёмки

- [ ] В пайплайне с двумя графами, использующими один и тот же чекпоинт модели (например, один backbone для text-to-image и image-to-image), в памяти создаётся **один экземпляр** этой модели; оба графа используют его при run.
- [ ] Аналогично для **любого уровня иерархии** (граф с двумя узлами с одним чекпоинтом; пайплайн с несколькими графами с одной моделью; этап с несколькими пайплайнами с одной моделью; мир с несколькими этапами с одной моделью): **без дублирования весов** в памяти. Один идентификатор модели/чекпоинта → один экземпляр, переиспользуемый всеми процессами и всеми местами использования.
- [ ] Поведение при run (результаты, корректность) не отличается от случая «каждый узел со своей копией»; различие только в потреблении памяти и в том, что одна и та же модель переиспользуется.
- [ ] Для LLM по API: один и тот же model_id / endpoint — один клиент или общий пул запросов; не создавать отдельный «экземпляр» на каждый узел, если конфиг указывает на одну и ту же модель.

---

## 6. Связь с другими документами

| Документ | Связь |
|----------|--------|
| [SERIALIZATION_AT_ALL_LEVELS.md](SERIALIZATION_AT_ALL_LEVELS.md) | Сериализация и загрузка из чекпоинта на каждом уровне; механизм повторного использования не дублирует веса при загрузке — один ref → один экземпляр. |
| [Pipeline_Level.md](Pipeline_Level.md) | Пайплайн как граф графов; два графа с одним чекпоинтом — типичный сценарий повторного использования. |
| [LLM_API_SUPPORT.md](LLM_API_SUPPORT.md) | Для LLM по API «повторное использование» — один клиент/пул на один model_id/endpoint. |
| [TRAINING_REUSE_AND_API_SCENARIOS.md](TRAINING_REUSE_AND_API_SCENARIOS.md) | Обучение при повторном использовании: дедупликация параметров в оптимизаторе, градиенты с нескольких мест, чекпоинт один раз на ref, LoRA при общем блоке, обходы. |

Итого: **фреймворк должен предоставлять механизм повторного использования абсолютно одинаковых моделей без создания нескольких копий в памяти.** Любая модель (backbone, solver, codec, conditioner, tokenizer, adapter, guidance, LLM, VLM и т.д.) при полной идентичности (один чекпоинт / один model_id) **инициализируется один раз и переиспользуется во всех местах использования независимо от уровня иерархии** (граф, пайплайн, этап, мир). Никакого лишнего потребления памяти.
