# Обучение, повторное использование моделей и API: сценарии, коллизии и обходы

Подробное описание случаев, когда **обучают LoRA, мир, этап, пайплайн или граф**, а модели **используются повторно** (один экземпляр на несколько узлов/графов); что при этом происходит, какие бывают **коллизии**, как их решать и какие есть **обходные пути**. Отдельно — **обучение и LoRA для мира в контексте API-провайдеров** и дополнительные проблемные сценарии.

Канон: [MODEL_REUSE.md](MODEL_REUSE.md), [LLM_API_SUPPORT.md](LLM_API_SUPPORT.md), [TRAINABILITY_AT_ALL_LEVELS.md](TRAINABILITY_AT_ALL_LEVELS.md), [LORA_WORLD_LIGHTWEIGHT_CUSTOM.md](LORA_WORLD_LIGHTWEIGHT_CUSTOM.md).

---

## 1. Повторно используемые веса и обучение: что происходит

### 1.1 Ситуация

По [MODEL_REUSE.md](MODEL_REUSE.md) **один checkpoint_ref (или model_id) → один экземпляр блока в памяти**. Несколько узлов графа, несколько графов в пайплайне или несколько пайплайнов в этапе/мире могут **делить один и тот же блок** (одни и те же веса). При этом мы хотим **обучать**: отдельный граф, пайплайн, этап или весь мир (в т.ч. с LoRA).

### 1.2 Что происходит по шагам

1. **Сборка:** при построении графа/пайплайна/этапа/мира блоки с одинаковым `checkpoint_ref` (или `model_id` для API) создаются один раз; все «места использования» получают ссылку на один и тот же объект блока.
2. **Выбор обучаемых сущностей:** на уровне графа/пайплайна/этапа/мира задаётся, какие узлы (или графы, пайплайны) помечены как `trainable`. У блока с весами вызывается `trainable_parameters()`; оптимизатор получает итератор параметров.
3. **Коллизия:** если один и тот же блок используется в **нескольких узлах** (или в нескольких графах), то при вызове `trainable_parameters()` на уровне графа/пайплайна мы можем **один и тот же набор параметров передать в оптимизатор несколько раз** — по одному разу на каждый узел/граф, где этот блок фигурирует. Тогда:
   - **Оптимизатор:** один и тот же параметр зарегистрирован несколько раз → градиенты по нему могут накапливаться или обновление применяться несколько раз за шаг (двойной учёт).
   - **Чекпоинт:** веса блока в памяти одни; при сохранении их нужно сохранить **один раз**, а не по числу «мест использования».
4. **Forward/backward:** при одном проходе (run графа/пайплайна с `training=True`) блок может вызываться **несколько раз** (из разных узлов или в разных графах). Градиенты по его параметрам при backward **суммируются** со всех вызовов (если не делать специальных мер). Это либо желательно (общий блок обучается по всем использованиям), либо нежелательно (хотим обучать только по одному месту).

Итого: при обучении с повторно используемыми моделями ключевые моменты — **не дублировать параметры в оптимизаторе** и **однозначно решить, как обрабатывать градиенты** (суммировать по всем использованиям vs обучать только по одному месту).

---

## 2. Коллизии и способы решения

### 2.1 Дублирование параметров в оптимизаторе

**Коллизия:** при сборе `trainable_parameters()` из графа (или пайплайна) мы обходим узлы и для каждого trainable-узла добавляем параметры его блока. Если блок один и тот же у узлов A и B, мы добавим его параметры дважды. Оптимизатор будет применять обновление к одному и тому же тензору дважды за шаг → неверная динамика обучения.

**Решения:**

- **Дедупликация по идентификатору блока:** при сборке списка параметров для оптимизатора использовать **пул по checkpoint_ref / model_id / id(block)**. Каждый уникальный блок (по ref или по объекту) добавляется в оптимизатор **один раз**. Все узлы/графы, ссылающиеся на этот блок, разделяют одни и те же параметры в оптимизаторе.
- **Явный контракт:** граф/пайплайн при вызове `trainable_parameters()` возвращает параметры с дедупликацией (внутри — множество по id(block) или по checkpoint_ref). Документировать: «повторно используемый блок учитывается в оптимизаторе один раз».

**Обход:** если по какой-то причине дедупликация недоступна, единственный безопасный вариант — **не помечать оба узла как trainable** одновременно; помечать trainable только один узел, использующий общий блок (см. ниже «обучение только по одному месту»).

---

### 2.2 Градиенты с нескольких «мест использования»

**Коллизия:** один блок вызывается в узле 1 и в узле 2. При backward градиенты по параметрам блока приходят и от узла 1, и от узла 2. По умолчанию PyTorch (и аналог в JAX) **суммирует** градиенты при повторном использовании одного и того же параметра в графе. Итог: блок обновляется с учётом потерь **по всем местам использования**. Это часто желательно (одна модель учится на всех задачах), но не всегда.

**Варианты поведения:**

| Цель | Решение |
|------|--------|
| Обучать общий блок по **всем** использованиям | Оставить как есть: один раз в оптимизаторе, градиенты суммируются. Чекпоинт сохраняет блок один раз. |
| Обучать общий блок **только по одному** месту (например, только по графу G1) | При сборке графа обучения помечать trainable только узлы/графы, входящие в выбранную ветку; остальные узлы с тем же блоком — frozen. Либо выполнять forward/backward только для выбранного подграфа (один граф в пайплайне, один этап в мире). |
| Обучать **независимо** две копии одной и той же архитектуры | **Отключить повторное использование** для этого случая: в конфиге задать два разных `checkpoint_ref` (например, два пути к одному и тому же файлу — тогда пул даст один экземпляр) или явный флаг «clone for training» — при подготовке к обучению создать копию блока для одной из веток, чтобы получилось два экземпляра. Тогда в оптимизаторе две группы параметров, градиенты не смешиваются. |

**Рекомендация:** по умолчанию считать, что **общий блок обучается по всем местам использования** (градиенты суммируются); при необходимости «обучить только здесь» — сужать множество trainable узлов/графов или использовать клонирование для обучения.

---

### 2.3 Чекпоинт: один блок — один раз

**Коллизия:** при сохранении графа/пайплайна/этапа/мира мы сохраняем `state_dict` по узлам. Если у двух узлов один и тот же блок, не нужно записывать веса дважды.

**Решение:**

- **Сериализация по ref:** при `state_dict()` на уровне графа/пайплайна собирать state по **уникальным блокам** (по checkpoint_ref или id(block)). В конфиге/чекпоинте хранить: для каждого `checkpoint_ref` — один `state_dict`; в структуре графа узлы ссылаются на ref. При загрузке: один ref → один экземпляр блока, один раз загружаем веса.
- **Формат чекпоинта:** например, `checkpoints/shared/backbone.pt` и в метаданных графа указание «узел A и узел B используют ref shared/backbone.pt». При сохранении пишем один файл для этого ref.

**Обход:** если текущая реализация пишет state по node_id, то при повторном использовании блока два узла будут ссылаться на один и тот же объект; при сохранении по узлам можно сохранить один раз (для «первого» узла с этим блоком), а при загрузке — загрузить в блок один раз и убедиться, что оба узла ссылаются на этот блок. Документировать соглашение.

---

### 2.4 LoRA при повторно используемом блоке

**Сценарий:** один backbone используется в двух графах пайплайна (G1 и G2). Мы хотим LoRA: базовый backbone заморожен, обучаются только адаптеры.

**Варианты:**

- **Один общий LoRA на оба использования:** один блок, один LoRA-адаптер, инжектирован в блок. Оба графа используют блок+LoRA; LoRA обучается по данным и от G1, и от G2. Параметры в оптимизаторе: backbone (frozen) + LoRA (один раз). Чекпоинт: backbone один раз (или ref) + один файл LoRA.
- **Два отдельных LoRA (по одному на граф):** один и тот же блок, но к нему подключены **два разных LoRA-модуля** — например, при вызове из G1 используется LoRA_A, при вызове из G2 — LoRA_B. Реализация: блок принимает опциональный «контекст» (graph_id / node_id) или при run графа выбирается свой адаптер по правилу (по ref + graph_id). В оптимизаторе: backbone (frozen) + LoRA_A + LoRA_B. Чекпоинт: backbone один раз + lora_g1.pt + lora_g2.pt. При инференсе нужно указывать, какой граф (какой LoRA применять).

**Коллизия:** если реализовать «два LoRA» как два полных клона блока с LoRA, мы потеряем выгоду повторного использования (два набора весов backbone в памяти). Поэтому корректная схема: **один экземпляр блока**, несколько экземпляров LoRA-адаптеров, переключаемых по контексту вызова (graph_id, stage_id и т.д.).

**Обход:** если «контекстный» LoRA сложен, можно временно отключить повторное использование для этого пайплайна (два графа — два экземпляра блока, у каждого свой LoRA). Память растёт, зато логика проще; документировать как опцию для отладки или особых сценариев.

---

## 3. Пошаговые действия при обучении с повторным использованием

### 3.1 Обучение графа, где несколько узлов делят один блок

1. Собрать граф как обычно; пул по checkpoint_ref обеспечивает один экземпляр блока на несколько узлов.
2. Пометить trainable нужные узлы (`set_trainable(node_id, True)`). Блок общий — он будет trainable, если trainable хотя бы один узел с этим блоком.
3. При сборе параметров для оптимизатора **дедуплицировать по блоку** (по checkpoint_ref или id(block)), чтобы каждый блок учитывался один раз.
4. Forward: run(graph, inputs, training=True). Backward: loss.backward(). Градиенты в общий блок приходят со всех вызовов этого блока.
5. Сохранение: state_dict по уникальным блокам (или по ref); один ref → один файл/одна запись в чекпоинте.

### 3.2 Обучение пайплайна (два графа с общим чекпоинтом)

1. Пайплайн собран; G1 и G2 используют один и тот же checkpoint_ref для backbone (один экземпляр в памяти).
2. Решить: обучаем общий backbone по обоим графам или только по одному. Если по обоим — оба графа trainable, дедупликация параметров при сборке оптимизатора. Если только по G1 — помечать trainable только граф G1 (или только узлы внутри G1); G2 frozen.
3. run_pipeline(..., training=True): сначала G1, потом G2 (по топологии). Backward по выбранной политике (все графы или только G1). Чекпоинт: один state для общего блока + по графам только уникальные блоки.

### 3.3 Обучение этапа или мира с общими моделями

Аналогично: на уровне этапа/мира задаётся множество trainable пайплайнов/этапов. При сборе trainable_parameters() рекурсивно по всем узлам и **дедупликация по checkpoint_ref** на всём пути. Один ref в любом графе любого пайплайна любого этапа → один раз в оптимизаторе. Forward/backward по полной топологии; градиенты в общие блоки суммируются. Сохранение мира/этапа: один чекпоинт на каждый уникальный ref во всей иерархии.

---

## 4. LoRA и обучение мира при API-провайдерах

### 4.1 Ограничение

Блоки в режиме **«только API»** ([LLM_API_SUPPORT.md](LLM_API_SUPPORT.md)) **не имеют локальных весов**: инференс идёт через HTTP к провайдеру. **Обучать локально нечего** — нет параметров в процессе. Исключение: провайдер сам предоставляет fine-tuning (OpenAI fine-tuning, и т.д.) — это отдельный внешний процесс, не «backward» внутри фреймворка.

### 4.2 Что должно происходить

| Сценарий | Ожидаемое поведение |
|----------|----------------------|
| Мир/этап/граф содержит узлы только с API | Нет локальных обучаемых параметров для этих узлов. `trainable_parameters()` для таких блоков пуст. Обучение «мира» в этом случае — только те блоки, которые локальные (если есть), или только адаптеры (см. ниже). |
| Мир смешанный: часть узлов — API, часть — локальные | Trainable — только локальные блоки (и их LoRA, если подключены). API-блоки в расчёте loss участвуют (forward), но в backward не вносят градиентов. Loss может быть на выходе API-блока (например, reward по ответу LLM); тогда обучаются только **нисходящие** локальные блоки или **обёртки** вокруг API. |
| LoRA «на весь мир», но часть блоков — API | К API-блокам **нельзя подключить локальную LoRA** к весам провайдера (весов нет локально). Варианты: (1) не подключать LoRA к API-блокам; (2) обучить **локальные адаптеры другого рода** — см. ниже. |

### 4.3 Локальные адаптеры при API-блоках

Чтобы что-то «обучать» в сценарии с API, используют не веса провайдера, а **локальные обёртки**:

- **Промпт-адаптер (prompt tuning):** перед вызовом API к промпту добавляется обучаемый префикс/суффикс (несколько токенов или эмбеддингов). Обучаются только эти параметры; вызов API с модифицированным промптом. Блок в графе: «API-клиент + промпт-адаптер»; trainable_parameters() возвращает параметры адаптера.
- **Пост-обработка выхода:** блок «API + обучаемый слой» — ответ API проходит через маленькую локальную сеть (например, линейный слой или маппинг). Обучаются только эти слои. Loss на выходе этого блока; backward идёт только по локальной части.
- **Кэш/интерпретатор:** локальный кэш ответов или интерпретатор (правила, фильтры) с обучаемыми параметрами; вызов API даёт вход для этого кэша/интерпретатора. Обучается только локальная часть.

В контексте **LoRA для всего мира**: при обходе мира и подключении LoRA ко «всем нужным блокам» блоки с `backend: "api"` **пропускаются** для инжекции LoRA в веса (весов нет), но к ним можно **опционально** подключить один из адаптеров выше (промпт-адаптер, пост-обработка) и обучить его. В документации и конфиге явно разделять: «LoRA к весам» (только локальные блоки) и «адаптеры к API-узлам» (промпт/пост-обработка).

### 4.4 Пример сценария: мир с Автором и Философом по API, Творец — локальный

- Автор, Философ: LLM через API → локально не обучаются; можно добавить промпт-адаптеры и обучить их.
- Творец: локальный граф (диффузия) → можно обучать LoRA на backbone, полный fine-tune по конфигу и т.д.
- При «обучении мира» в оптимизатор попадают: промпт-адаптеры Автора/Философа (если есть) + параметры Творца (и его LoRA). API-вызовы только в forward; backward только по локальным частям.

---

## 5. Дополнительные проблемные сценарии и обходы

### 5.1 Хотим обучить backbone только в одном из двух графов пайплайна

**Проблема:** G1 и G2 делят один backbone. Нужно обучить backbone только по loss от G1, без влияния G2.

**Обходы:**

- **Заморозить G2:** пометить граф G2 (или все его узлы) как не trainable. Тогда backward не пойдёт в G2, градиенты в общий backbone придут только из G1.
- **Клон для обучения:** перед обучением создать копию блока только для G2 (отключить повторное использование для G2 в этой сессии). Тогда в памяти два backbone: один общий с G1 (trainable), второй только в G2 (frozen или не trainable). Память выше, зато полная изоляция.

### 5.2 Разные версии LoRA для одного и того же ref в разных этапах

**Проблема:** в мире этапы «Автор» и «Архитектор» оба используют один и тот же LLM (один model_id). Хотим у Автора один LoRA, у Архитектора — другой.

**Решение:** один экземпляр блока LLM (или один API-клиент), два LoRA-модуля: при run этапа Автор вызывается блок + LoRA_author, при run этапа Архитектор — блок + LoRA_architect. Контекст вызова (stage_id или role) выбирает, какой LoRA применить. Сохранение: один ref для базовой модели + `lora_author.pt` + `lora_architect.pt`. Загрузка: загружаем базовый блок один раз, загружаем оба LoRA, при run по stage_id подключаем нужный.

### 5.3 Загрузка чекпоинта при повторном использовании

**Проблема:** в чекпоинте один файл на checkpoint_ref; в графе три узла ссылаются на этот ref. При загрузке не должны прочитать файл три раза и не должны создать три экземпляра.

**Решение:** при load_from_checkpoint (или аналоге) сначала строим граф по конфигу с пулом ref→block; для каждого уникального ref создаётся один блок. Затем загружаем state: для каждого ref один раз читаем state_dict и вызываем block.load_state_dict(). Все узлы, ссылающиеся на этот ref, уже держат ссылку на тот же объект блока — дополнительных действий не нужно.

### 5.4 API: один model_id в многих узлах — лимиты и квоты

**Проблема:** десять узлов в мире используют один и тот же model_id (один клиент API). Много параллельных запросов → превышение rate limit или квоты провайдера.

**Обходы:**

- **Один клиент, очередь:** все узлы используют один экземпляр API-клиента с внутренней очередью и (опционально) ограничением частоты запросов. Документировать: при повторном использовании API-модели рекомендуется один клиент на process/на мир.
- **Батчинг:** где возможно, собирать запросы к одному model_id в батч (если провайдер поддерживает batch API) и отправлять одним вызовом.
- **Конфиг:** max_concurrent_requests, retry_with_backoff — в конфиге блока или клиента API.

### 5.5 Loss на выходе API-блока: что можно обучить

**Проблема:** loss вычисляется по выходу узла, который вызывает API. Через API backward не идёт.

**Что можно обучить:** только блоки, которые **выше по графу** (дают вход в API-блок) и являются локальными: промпт-адаптер, энкодер, предобработка. Обучение идёт так: forward до API → вызов API → forward после API → loss → backward до API-блока (градиенты останавливаются на границе API); обновляются только локальные параметры до API.

### 5.6 Сериализация «кто какой ref использует»

**Проблема:** при сохранении графа/пайплайна/мира нужно однозначно записать, какие узлы/графы используют какой checkpoint_ref, чтобы при загрузке правильно восстановить пул и не дублировать блоки.

**Решение:** в конфиге узла/графа явно хранить `checkpoint_ref` (или `model_id` для API). При сохранении state_dict собирать по уникальным ref; в метаданных или в структуре конфига список пар (node_id, ref) или (graph_id, ref) для проверки и документации. При загрузке: по ref создаём или достаём блок из пула, вешаем на соответствующие узлы/графы.

---

## 6. Краткая сводка

| Вопрос | Ответ |
|--------|--------|
| Один блок в нескольких узлах — как обучать? | Дедупликация параметров в оптимизаторе (один раз на блок). Градиенты по умолчанию суммируются со всех использований. |
| Обучить только по одному месту использования? | Пометить trainable только нужные узлы/графы или выполнять backward только по выбранной ветке; либо клонировать блок для второй ветки. |
| Чекпоинт при повторном использовании? | Сохранять state по уникальным checkpoint_ref (один раз на ref); при загрузке один ref → один блок, один load_state_dict. |
| LoRA при общем блоке в двух графах? | Либо один общий LoRA на оба, либо два LoRA (по графу/этапу), переключаемые по контексту вызова; блок один в памяти. |
| Обучение мира при API-узлах? | API-блоки не дают локальных параметров. Обучаются локальные блоки и локальные адаптеры (промпт-адаптер, пост-обработка). |
| LoRA «на весь мир» с API? | LoRA к весам — только у локальных блоков; у API-блоков можно опционально обучать промпт/пост-адаптеры. |

Связь с каноном: [MODEL_REUSE.md](MODEL_REUSE.md), [LLM_API_SUPPORT.md](LLM_API_SUPPORT.md), [TRAINABILITY_AT_ALL_LEVELS.md](TRAINABILITY_AT_ALL_LEVELS.md), [LORA_WORLD_LIGHTWEIGHT_CUSTOM.md](LORA_WORLD_LIGHTWEIGHT_CUSTOM.md).
