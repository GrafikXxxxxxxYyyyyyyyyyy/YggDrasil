# Техническое задание: рефакторинг YggDrasil в полноценный Lego-конструктор диффузионных моделей

**Версия:** 1.2  
**Дата:** 15 февраля 2025  
**Цель:** Универсальный Lego-конструктор **любых** диффузионных решений **любой** модальности: единая иерархия (блок = узел графа, стадия = граф блоков, пайплайн = граф стадий), максимальная гибкость для разработчиков, возможность создавать собственную модальность, модель, пайплайн и обучать всё это.

### Статус реализации (по ТЗ)

- **Сделано:** AbstractBaseBlock — единый базовый блок; абстракции уровня 1 (Backbone, Codec, Conditioner, Guidance, Solver, Adapter, InnerModule, OuterModule, Processor); AbstractStage; ComputeGraph с `add_node(type="...", auto_connect=True)` и `add_stage(..., auto_connect_to_previous=..., auto_connect_by_ports=...)` (п. 4.2: авто-подключение стадий по портам — последняя стадия без исходящего «output» соединяется с новой); InferencePipeline (from_config, from_pretrained, from_template, from_graph, **from_diffusers**, from_combined); TrainingPipeline (from_config, from_pretrained, **from_template**, from_graph, train_stages, train_nodes с префиксом стадии `stage0/lora`); составной пайплайн (YAML `kind: combined_pipeline`, stages + links); **from_workflow** и **Runner** поддерживают combined pipeline; **to_yaml** и **to_workflow** сериализуют combined pipeline (AbstractStage → kind: combined_pipeline, stages с вложенным graph); пример конфига `combined_t2i_img2img.yaml`; в графе только узлы типа solver/…, параметры расписания в solver_config (п. 2.9); шаблоны первой очереди зарегистрированы и покрыты тестами. **Интеграция Diffusers (п. 15):** единый Solver (без отдельного Scheduler), копирование config из diffusers scheduler в solver; DiffusersBridge.import_pipeline задаёт metadata; InferencePipeline.from_diffusers(pipe); для «плоского» графа (без denoise_loop) автоматический цикл сэмплинга в InferencePipeline. **Деплой (п. 16):** Modal и RunPod переведены на единый интерфейс InferencePipeline (from_pretrained / from_template / from_graph).
- **Полная поддержка моделей (п. 13, первая очередь):** SD 1.5 (txt2img, img2img, inpainting, nobatch), SDXL (txt2img, img2img, inpainting, refiner), SD3 (txt2img, img2img), FLUX.1 (txt2img, img2img), FLUX.2 (txt2img, schnell, fill, canny, depth, redux, kontext, klein). Адаптеры: ControlNet для SD 1.5 и SDXL (controlnet_txt2img, controlnet_sdxl_txt2img), add_controlnet_to_graph; IP-Adapter с автоопределением cross_attention_dim (768/2048) по base_model; T2I-Adapter. LoRA: загрузка в UNet (SD 1.5/SDXL) и в transformer (FLUX/SD3 при backbone с ._model и load_lora_weights). Шаблоны обучения: train_lora_sd15, train_lora_sdxl, train_lora_flux, train_lora_sd3. Метаданные base_model в шаблонах для корректной работы адаптеров. Тесты: tests/test_model_families.py (регистрация шаблонов, base_model, ControlNet, IP-Adapter, LoRA).
- **Рефакторинг закрыт.** Все 12 критериев приёмки (раздел 9) и этапы фаз 1–5 выполнены. Детальный чеклист — в REFACTORING_STATUS.md. Дополнительные сценарии и тяжёлые E2E-тесты — по мере необходимости при наличии зависимостей.

---

## 1. Цели и границы проекта

### 1.1 Цели

1. **Единый базовый кирпичик (Block):** любой элемент фреймворка наследует абстрактный базовый блок (AbstractBaseBlock). Идея блока и идея графа объединены: **любой блок может быть узлом в графе**; граф — композиция блоков-узлов и рёбер.
2. **Графовая сборка:** на уровне стадии граф составлен из блоков уровня 1 (Backbone, Codec, …); на уровне пайплайна граф составлен из узлов AbstractStage (каждая стадия сама — граф блоков). Пользователь и TrainingPipeline работают с **единым графом** (граф стадий).
3. **Любая диффузионная модель и любая модальность:** поддержка **любых** диффузионных решений (изображение, видео, аудио, молекулы, временные ряды, 3D, текст и т.д.) и **любой** модальности, включая будущие и **собственную модальность пользователя** (регистрация своей модальности через плагин/абстракции).
4. **Собственная модель, пайплайн, обучение:** разработчик может реализовать **собственную диффузионную модель** (наследуя Backbone, Codec, Conditioner и т.д.), **собственный пайплайн** (граф стадий и графы блоков внутри стадий) и **обучить любое обучаемое** (блоки, стадии, весь пайплайн) через единый TrainingPipeline.
5. **Конечный набор абстрактных ролей:** любой диффузионный процесс раскладывается на фиксированный набор абстрактных сущностей уровня 1; конкретные реализации наследуются от соответствующих абстракций и регистрируются как узлы графа.
6. **Простой интерфейс:** инференс и обучение «в три строки» через InferencePipeline и TrainingPipeline.
7. **Гибкость для разработчика:** добавление узла с автоопределением роли; регистрация **собственных блоков**, **собственной модальности** (плагин), **собственных шаблонов стадий и пайплайнов** без изменения ядра.
8. **Комбинирование:** пайплайн = граф AbstractStage; составные сценарии — граф стадий, один запуск и обучение через InferencePipeline / TrainingPipeline.
9. **Расширяемость:** расширение AbstractBaseBlock без нарушения принципа «блок = узел графа».

### 1.2 Внешние интеграции (поддержка)

- Пользовательские обученные модели (свои веса, свои конфиги).
- Официальная библиотека **Diffusers** (Hugging Face).
- **ComfyUI** (импорт/экспорт workflow при возможности).
- **Automatic1111** (интеграция/совместимость по мере возможности).
- **Деплой** на любую удалённую платформу: облако, endpoint, сервер (уже заложено в deployment/; требуется сохранить и усилить).

### 1.3 Универсальность и гибкость (обязательные требования)

- **Любые диффузионные решения:** фреймворк должен поддерживать **любую** известную и будущую диффузионную модель и **любую** модальность (изображение, видео, аудио, молекулы, временные ряды, 3D, текст, и т.д.).
- **Собственная модальность:** возможность **создать и зарегистрировать собственную модальность** (например, через плагин с набором блоков и шаблонов стадий), не меняя ядро.
- **Собственная диффузионная модель:** возможность **реализовать собственную модель** (свой Backbone, Codec, Conditioner, Solver и т.д.), наследуя абстракции уровня 1, и использовать её как узел в графе стадии.
- **Собственный пайплайн:** возможность **собрать собственный пайплайн** (граф стадий и графы блоков внутри стадий) из стандартных и собственных блоков, сохранить в конфиг и запускать через InferencePipeline / TrainingPipeline.
- **Обучить всё:** возможность **обучить** любой обучаемый блок, любую стадию, любой набор стадий или весь пайплайн через TrainingPipeline с явным выбором обучаемых узлов и стадий.

### 1.4 Принцип Lego-конструктора (философия кода)

Код должен быть **максимально похож на Lego-конструктор**: предельная гибкость, масштабируемость, возможность собрать и обучить **что угодно**, реализовать **любые смелые идеи** разработчика. Блоки стыкуются, комбинируются и масштабируются без жёстких ограничений; пользователь свободен в своих решениях.

### 1.5 Первая очередь моделей

На первом этапе фокус на полной поддержке и стабильной работе с:

- **Stable Diffusion 1.5**
- **Stable Diffusion XL**
- **FLUX.1**
- **FLUX.2 Klein**
- **Stable Diffusion 3**

---

## 2. Архитектура: блок как кирпичик и единая идея графа

### 2.1 Принципы (тезисно)

1. **Блок = узел графа.** Всё в фреймворке — блок (наследник AbstractBaseBlock); любой блок может быть узлом графа. Граф — композиция блоков-узлов и рёбер (порты).
2. **Два уровня графа.** Граф стадии: узлы = блоки уровня 1 (Backbone, Codec, …). Граф пайплайна: узлы = AbstractStage (каждая стадия сама — граф блоков). Для пользователя пайплайн — **один граф** (граф стадий).
3. **Любая модальность, свой пайплайн, обучить всё.** Поддержка любых диффузионных решений и модальностей; возможность создать свою модальность, свою модель, свой пайплайн и обучить любое обучаемое.
4. **Расширяемость без ломания ядра.** Регистрация своих блоков, плагинов, шаблонов; расширение AbstractBaseBlock — без нарушения «блок = узел».

### 2.2 Идея блока и графа (развёрнуто)

- **Базовый кирпичик — Block (AbstractBaseBlock).** Всё в фреймворке наследует эту идею блока.
- **Блок и граф объединены:** любой блок может быть **узлом в графе**; граф — композиция блоков (узлов) и рёбер между портами. Блок всегда может выступать узлом; граф всегда составлен из блоков-узлов.
- **Иерархия уровней:** на каждом уровне сущности наследуют базовый блок и используются **как узлы в графе** соответствующего уровня.

### 2.3 Иерархия уровней (блоки как узлы графа)

```
Уровень 0: AbstractBaseBlock — базовый кирпичик
    │
    │  Любой блок = узел графа. Всё в фреймворке наследует Block.
    │
Уровень 1: Специализированные абстракции (наследуют AbstractBaseBlock, используются как узлы графа стадии)
    ├── AbstractBackbone
    ├── AbstractCodec
    ├── AbstractConditioner
    ├── AbstractGuidance
    ├── AbstractSolver
    ├── AbstractAdapter
    ├── AbstractInnerModule
    ├── AbstractOuterModule
    └── AbstractProcessor

Уровень композиции: AbstractStage
    │  Стадия = граф из блоков уровня 1. Сама AbstractStage тоже может быть узлом графа пайплайна.
    │
    └── AbstractStage = граф блоков (узлы = Backbone, Codec, …). Одна стадия — один такой граф.
        При этом AbstractStage сам выступает узлом в графе верхнего уровня (графе пайплайна).

Верхний уровень (интерфейс пользователя): Pipeline
    InferencePipeline / TrainingPipeline = выполнение одного графа, узлами которого являются AbstractStage.
    Каждый узел (AbstractStage) — в свою очередь граф из блоков уровня 1.
```

Итоговая картина для пользователя и разработчика:

- **Пайплайн (Inference / Training)** — один граф для всего: граф, узлы которого — **AbstractStage**. Пользователь и обучающий контур работают с этим единым графом.
- **Каждый AbstractStage** — граф, узлы которого — блоки уровня 1 (Backbone, Codec, Conditioner, Guidance, Solver, Adapter, InnerModule, OuterModule, Processor). Разработчик на уровне композиции собирает пайплайн из стадий и при необходимости отдельно собирает/редактирует граф одной стадии.
- **Разработчики и энтузиасты** на уровне блоков реализуют свои модели, солверы, guidance, кондиционеры, кодеки, бэкбоны, процессоры, внешние и внутренние модули, наследуя соответствующие абстракции уровня 1 (все они наследуют базовый блок и выступают узлами в графе стадии).
- **Разработчик проекта** должен иметь возможность расширять функциональность абстрактного базового блока (расширяемость AbstractBaseBlock), не ломая идею «блок = узел графа».

**Роли по уровням работы с графом:**

- **Пользователь:** работает с InferencePipeline / TrainingPipeline — единый граф (узлы = AbstractStage). Запуск инференса или обучения «в несколько строк».
- **Разработчик на уровне композиции:** собирает пайплайн как граф из AbstractStage; при необходимости отдельно собирает или правляет граф одной стадии (граф блоков внутри выбранной AbstractStage).
- **Разработчик / энтузиаст на уровне блоков:** реализует свои модели, солверы, guidance, кондиционеры, кодеки, бэкбоны, процессоры, внутренние и внешние модули, наследуя соответствующие абстракции уровня 1 (все они наследуют AbstractBaseBlock и выступают узлами в графе стадии).
- **Разработчик проекта:** расширяет контракт или поведение AbstractBaseBlock (новые методы, метаданные для графа, порты), сохраняя совместимость с «блок = узел графа».

Требования:

- **Любой** блок в конструкторе наследует `AbstractBaseBlock` и может быть узлом в графе.
- Конкретные реализации (UNet, VAE, CLIP, ControlNet, Euler, обёртка внешней модели и т.д.) наследуют одну из абстрактных ролей уровня 1 и используются как узлы в графе стадии. Целые пайплайны (Detailer, Upscaler) задаются как **AbstractStage** (граф блоков), а не как один блок.

### 2.4 AbstractBaseBlock (базовый кирпичик)

- Единственная базовая сущность для всех блоков. **Любой блок является потенциальным узлом графа**; идея блока и идея графа объединены: граф составляется из блоков-узлов и рёбер между портами.
- Обязательный контракт:
  - `declare_io()` — порты ввода/вывода (типизированные).
  - `process(**port_inputs) -> dict` — выполнение по портам.
- Опционально: слоты для вложенных блоков (legacy-совместимость), хуки, сохранение/загрузка.
- Все сущности фреймворка (backbone, codec, conditioner, guidance, solver, adapter, inner/outer module, processor и т.д.) строятся **только** на этом базисе. **Разработчик проекта должен иметь возможность расширять функциональность AbstractBaseBlock** (новые методы, контракты, метаданные для графа) без нарушения принципа «блок = узел графа».

### 2.5 AbstractBackbone

- Уже есть в `core/model/backbone.py`.
- Роль: основная модель предсказания (шум/скорость/x0) в латентном пространстве.
- Порты: `x`, `timestep`, `condition`, `position_embedding`, `adapter_features` (опционально), выход `output`.
- Слоты: `adapters` (multiple, optional) для инъекции Inner-модулей (ControlNet, T2I и т.д.).

### 2.6 AbstractCodec

- Уже есть как `AbstractLatentCodec` в `core/model/codec.py`.
- Роль: кодирование/декодирование между пиксельным и латентным пространством (или иными представлениями).
- Контракт: `encode()` / `decode()` или эквивалент через `process()`.

### 2.7 AbstractConditioner

- Уже есть в `core/model/conditioner.py`.
- Роль: преобразование сырого условия (текст, изображение, класс и т.д.) в эмбеддинги.
- Порты: `raw_condition` → `embedding`, `pooled_embedding`, `attention_mask` и т.д.

### 2.8 AbstractGuidance

- Уже есть в `core/model/guidance.py`.
- Роль: применение guidance к выходу модели (CFG, PAG, SAG, FreeU и т.д.).
- Порты: `model_output`, `uncond_output` (опц.), `condition`, `x`, `t` → `guided_output`.

### 2.9 AbstractSolver (объединение с Scheduler)

- **Требование:** в системе остаётся только понятие **Solver**. Понятие «Scheduler» как отдельная сущность **устраняется**.
- Solver отвечает за:
  - расписание шагов (timesteps) — то, что в Diffusers делается Scheduler;
  - один шаг обратного процесса: `step(model_output, current_latents, timestep, process, ...) -> next_latents`.
- Все текущие блоки типа «scheduler» (EulerDiscreteScheduler, PNDMScheduler и т.д.) должны быть реализованы как **реализации AbstractSolver** (с внутренней логикой расписания).
- В графе и в конфигах — только узлы типа `solver/...`, без отдельного типа `scheduler/...`.

### 2.10 AbstractAdapter

- Общая абстракция для адаптеров (LoRA, DoRA, Hypernetwork и т.д.), которые модифицируют веса или вывод модели.
- Контракт: возможность «прикрепиться» к целевому блоку (например, к backbone), инъекция/применение в forward.
- LoRA: полная поддержка, в том числе **несколько LoRA-адаптеров** одновременно.

### 2.11 AbstractInnerModule

- **Роль:** модуль, встраиваемый **в сам процесс деноайзинга** — т.е. внутрь цикла обратной диффузии, на каждый шаг solver’а. Он является частью «ядра» генерации, а не дополнением сбоку.
- Примеры: ControlNet, T2I-Adapter — получают латенты, таймстеп, условие и отдают дополнительные признаки в backbone (`adapter_features`).
- В графе: при добавлении узла типа Inner граф подключает его к входу `adapter_features` backbone’а внутри цикла деноайзинга и при необходимости добавляет вход графа (например, `control_image`).

### 2.12 AbstractOuterModule

- **Роль:** обёртка над **внешней моделью или сервисом**, подключаемой к пайплайну «сбоку» — т.е. не часть диффузионного цикла и не отдельная генеративная стадия. Это «дополнение» в виде вызова внешней системы: распознавание лиц, детекция объектов, классификатор, любой внешний API или модель для произвольной задачи.
- **Не путать с Detailer/Upscaler:** пайплайны типа Detailer и Upscaler — это **генеративные процессы**, их корректно описывать как **AbstractStage** (отдельная стадия с собственным графом: backbone, solver, codec и т.д.). AbstractOuterModule — именно для **внешних** (не диффузионных или не наших) моделей: детектор лиц, детектор объектов, сегментация, классификация и т.п.
- Вход/выход: произвольные (изображение/видео/тензор → результат внешней модели: боксы, маски, эмбеддинги, флаги и т.д.).
- В графе: подключается до или после стадии, передаёт данные во внешнюю модель и возвращает результат в граф.

### 2.13 AbstractProcessor (новая сущность)

- **Роль:** предобработка и постобработка данных (единая абстракция для pre- и post-processing).
- Вход: сырые или промежуточные данные (изображение, видео, аудио, тензор).
- Выход: данные в формате, готовом для следующего блока или стадии (resize, normalize, crop, to tensor, или обратное преобразование после генерации).
- Примеры: image_processor (resize, normalize для control_image), video_processor, подготовка изображения для следующей стадии, финальная нормализация выхода.
- В графе: узел типа Processor может стоять в начале стадии (pre), в конце (post) или между блоками внутри стадии.

### 2.14 AbstractStage (уровень композиции)

- **Роль:** одна стадия пайплайна. AbstractStage — это **граф из блоков уровня 1** (узлы графа стадии = Backbone, Codec, Conditioner, Guidance, Solver, Adapter, InnerModule, OuterModule, Processor). В то же время **сама AbstractStage выступает узлом** в графе верхнего уровня: пайплайн (InferencePipeline / TrainingPipeline) — это **граф, узлами которого являются AbstractStage**. Таким образом, для пользователя и для обучения пайплайн — **один граф** (граф стадий); каждая стадия — граф блоков.
- Для одностадийного пайплайна этот граф имеет один узел (одна AbstractStage). Для многостадийного — несколько узлов-стадий; данные передаются с выхода одной стадии на вход следующей по рёбрам графа пайплайна.
- Содержимое стадии: ComputeGraph из блоков уровня 1. Prior-стадия, Detailer-, Upscaler-пайплайны задаются как **отдельные AbstractStage** (графы из этих блоков), а не как один блок.
- Внутри одной стадии можно комбинировать, например: AbstractProcessor (pre) → AbstractOuterModule (внешняя модель: детектор объектов, face recognition) → AbstractProcessor (подготовка) → диффузия.
- **Пример многостадийного пайплайна из четырёх AbstractStage:**
  - **Стадия 1:** AbstractProcessor (предобработка) → опционально AbstractOuterModule (внешняя модель: детекция объектов, распознавание лиц) → AbstractProcessor (подготовка для следующей стадии).
  - **Стадия 2:** одностадийная диффузия (текст→изображение); при необходимости апскейл — **отдельная стадия** (AbstractStage с графом апскейлера) или часть графа стадии 2.
  - **Стадия 3:** полноценный Image-to-Video пайплайн (AbstractStage).
  - **Стадия 4:** Video-to-Video пайплайн (AbstractStage) — улучшение согласованности кадров и качества.
- **Пример Kandinsky:** два AbstractStage — стадия 1 (prior): граф из блоков (например, Backbone/Conditioner/Solver), выход — эмбеддинг/латент; стадия 2: основной декодер (диффузия по этому латенту). Отдельного типа блока «Prior» нет.

### 2.15 MotionAdapter и прочие временные модули

- **MotionAdapter** (AnimateDiff и аналоги) реализуется **без введения новой абстракции** — существующим набором блоков: как **AbstractInnerModule** или **AbstractAdapter**, встраиваемый в backbone для добавления временного измерения. Отдельный абстрактный блок для motion не вводится.

---

## 3. Диффузионный процесс и многостадийный пайплайн

- **Одна стадия (один AbstractStage)** представляется графом из конечного набора абстрактных блоков: Backbone, Codec, Conditioner(’ы), Guidance, Solver, Adapter’ы, InnerModule’ы, OuterModule’ы, Processor’ы (pre/post). Prior-стадия (Kandinsky, Cascade и т.д.) — это просто первый AbstractStage с графом из тех же блоков (отдельный тип «Prior» не вводится).
- **Многостадийный пайплайн** — цепочка **AbstractStage**; выход стадии N подаётся на вход стадии N+1. Примеры: preprocess + detection → diffusion + upscale → I2V → V2V; Kandinsky = два AbstractStage (первая стадия — граф «prior», вторая — декодер).
- AbstractDiffusionProcess (математика forward/reverse) остаётся отдельным абстрактным блоком для формул диффузии; Solver использует его при шаге.

---

## 4. Граф вычислений (уровень разработчика)

### 4.1 Модель данных

- **Два уровня графа:**
  - **Граф стадии:** узлы = блоки уровня 1 (Backbone, Codec, Conditioner, Guidance, Solver, Adapter, InnerModule, OuterModule, Processor). Рёбра = соединения «выходной порт узла A» → «входной порт узла B». Один такой граф = одна AbstractStage.
  - **Граф пайплайна:** узлы = AbstractStage (каждый узел сам является графом блоков). Рёбра = передача данных с выхода одной стадии на вход другой. InferencePipeline / TrainingPipeline выполняют этот граф целиком (единый граф для пользователя).
- Узел графа на любом уровне — экземпляр блока (наследник AbstractBaseBlock) или AbstractStage (граф блоков, сам выступающий узлом).
- Входы/выходы графа объявляются явно (`expose_input`, `expose_output`).
- Конфигурация: YAML/JSON (граф стадии и/или граф пайплайна), сохраняемый и загружаемый workflow.

### 4.2 Механизм сборки графа: add_node и add_stage

**add_node (граф стадии):** добавление узла **максимально простое** — вызов `add_node(type="...")` без указания мест подключения. Граф **автоматически** определяет, куда подключить узел, по его роли в реестре.

- Пример: `stage_graph.add_node(type="ip_adapter")` → граф определяет роль (модификатор условия) → подключает к цепочке condition, добавляет вход `ip_image`.
- Пример: `stage_graph.add_node(type="controlnet")` → граф определяет роль (AbstractInnerModule) → подключает к `adapter_features` backbone, добавляет вход `control_image`.
- Разработчик **не определяет** соединения вручную — достаточно указать тип узла; позиция в графе определяется автоматически по роли (backbone, conditioner, inner, outer и т.д.).

Опционально: ручное соединение портов для продвинутых сценариев.

**add_stage (граф пайплайна):** добавление стадии — вызов `add_stage(stage)` или `add_stage(template="...")`. Стадии могут **самоопределять** свою последовательность в пайплайне по совместимости портов (какие входы требуют, какие выходы дают). Пайплайн не обязан быть строго линейным append — при добавлении стадии система определяет, куда её вставить (между какими стадиями, до/после каких узлов) по маппингу выход→вход. Пользователь добавляет стадии; порядок выстраивается по совместимости портов или задаётся явно при необходимости.

### 4.3 Автоопределение роли и места подключения (add_node)

При `add_node(type="...")` граф **автоматически** определяет роль блока и место подключения; разработчик **не задаёт** соединения вручную.

- Реестр блоков: метаданные `role` и правила подключения для каждой роли; граф определяет роль и место подключения (Inner → backbone.adapter_features; condition chain → conditioner; Outer → до/после стадии и т.д.).
- Примеры:
  - Пользователь добавляет узел «ControlNet» → граф определяет, что это AbstractInnerModule → подключает к `adapter_features` backbone’а внутри цикла деноайзинга и при необходимости добавляет вход графа `control_image`.
  - Пользователь добавляет узел «IP-Adapter» → граф определяет, что это модификатор условия (AbstractConditioner или интеграция с conditioner) → подключает к цепочке condition и при необходимости добавляет вход `ip_image`.
  - Пользователь добавляет узел «object_detector» (внешняя модель) → граф определяет, что это AbstractOuterModule → подключает до/после стадии. Пайплайны типа Upscaler/Detailer задаются как отдельная AbstractStage, а не как один блок Outer.
- Реализация: реестр блоков с метаданными «роль» (role: backbone | codec | conditioner | guidance | solver | adapter | inner_module | outer_module | processor); при `add_node(type="...")` граф по типу определяет роль и применяет правила подключения для данной роли.

### 4.4 Добавление и удаление компонентов

- В графе можно в любом порядке и в любом количестве:
  - добавлять и удалять узлы;
  - соединять и отключать рёбра;
  - комбинировать любые поддерживаемые компоненты фреймворка.
- Валидация: проверка совместимости портов (типы, опциональность), проверка DAG, опционально проверка «обязательные входы графа подключены».

### 4.5 Комбинирование графов: add_stage и порядок стадий

- **add_stage:** пайплайн собирается командой `add_stage(stage)` или `add_stage(template="...")`. Стадии могут **самоопределять** свою последовательность по совместимости портов (выходы одной стадии → входы другой). Пользователь добавляет стадии; порядок выстраивается автоматически по маппингу выход→вход, либо задаётся явно.
- **Требование:** многостадийный пайплайн = граф **AbstractStage**; каждая стадия — граф блоков; рёбра между стадиями = выход N → вход N+1 (или по совместимости портов при авто-упорядочивании).
- **Примеры сценариев:**
  - **Четыре стадии:** (1) AbstractProcessor (pre) + AbstractOuterModule (например, детекция объектов) + AbstractProcessor (подготовка) → (2) диффузия текст→изображение + апскейл → (3) Image-to-Video → (4) Video-to-Video (консистентность и качество).
  - **Kandinsky:** два AbstractStage — стадия 1 (текст → эмбеддинг/латент) и стадия 2 Decoder (диффузия по эмбеддингу).
  - **Text → Image → Upscale → I2V:** три–четыре стадии в зависимости от разбиения.
- **Модель данных:** составной пайплайн = упорядоченный список AbstractStage; маппинг выходов стадии N на входы стадии N+1 (например, `stage_1.outputs["images"]` → `stage_2.inputs["image"]`). Общие входы/выходы — входы первой стадии и выходы последней.
- **Конфигурация:** YAML/JSON задаёт список стадий (каждая — граф или шаблон) и связи выход→вход между стадиями.
- **Выполнение:** последовательный запуск стадий; данные между стадиями передаются в памяти.
- Запуск через **InferencePipeline** одним вызовом; обучение — через **TrainingPipeline** с указанием обучаемых стадий и узлов (см. п. 5.3, 6.1, 6.2).

---

## 5. Обучение

### 5.1 Обучение любого обучаемого блока

- Любой блок, у которого есть обучаемые параметры, должен поддерживать режим обучения.
- Пользователь должен иметь возможность **выбрать**, какие узлы/блоки обучать, а какие заморозить.
- В конфиге графа или в API обучения: явный список trainable nodes / trainable block types (или флаги по узлам).

### 5.2 LoRA и несколько LoRA

- Полная поддержка LoRA-адаптеров: загрузка, применение, сохранение.
- Поддержка **нескольких** LoRA одновременно (multi-LoRA): разные веса, разные имена адаптеров, комбинирование в одном backbone.

### 5.3 Обучение комбинированного (составного) пайплайна

- **Требование:** возможность обучать **весь составной пайплайн** или выбранные стадии/узлы внутри него.
- Пользователь задаёт составной пайплайн (несколько графов, объединённых в цепочку) и указывает:
  - какие **стадии** участвуют в обучении (например, только первая «текст→изображение», или первая + вторая «апскейл»);
  - внутри каждой стадии — какие **узлы** обучаемы (аналогично одиночному графу: train_nodes / trainable block types).
- Сценарии:
  - Обучение только одной стадии (например, LoRA на тексте→изображение), остальные стадии заморожены.
  - Обучение нескольких стадий (например, текста→изображение + апскейлер).
  - End-to-end обучение всего составного пайплайна (все обучаемые параметры всех стадий), при необходимости с разными lr по стадиям или по типам блоков.
- Градиенты: при последовательном выполнении стадий градиенты должны корректно проходить через маппинг выход→вход между стадиями (если стадия обучаемая). Реализация через единый граф обучения или через цепочку вызовов с сохранением промежуточных активаций и backward по цепочке.
- Интерфейс обучения составного пайплайна — тот же высокоуровневый класс **TrainingPipeline** (см. п. 6.2): инициализация из конфига составного пайплайна или из списка графов; метод `train(...)` с параметрами типа `train_stages=[0, 1]`, `train_nodes=["lora_adapter", "upscaler.encoder"]` и т.п.

---

## 6. Высокоуровневые классы для пользователя (уровень «три строки»)

### 6.1 InferencePipeline

- **Назначение:** единственный высокоуровневый класс для инференса, универсальный для всего фреймворка — в том числе для **одиночного** графа и для **комбинированного (составного)** пайплайна (несколько графов в цепочке).
- **Инициализация** (один из способов):
  - из файла конфигурации графа (YAML/JSON) — один граф;
  - из файла конфигурации **составного пайплайна** (YAML/JSON со списком стадий и маппингом выход→вход);
  - из pretrained-модели (HuggingFace ID или локальный путь);
  - из известного пайплайна генерации (Diffusers pipeline или зарегистрированный шаблон);
  - программно: сборка составного пайплайна из списка графов и правил связывания стадий (например, `InferencePipeline.from_combined([graph_txt2img, graph_upscale, graph_i2v], links=[...])`).
- **Интерфейс использования:** один и тот же вызов для одиночного и составного пайплайна — максимально простой, «в три строки», например:
  ```python
  # Одиночный пайплайн
  pipe = InferencePipeline.from_pretrained("runwayml/stable-diffusion-v1-5", device="cuda")
  result = pipe(prompt="a cat", num_steps=28, seed=42)
  image = result.images[0]

  # Составной пайплайн: текст → изображение → апскейл → изображение в видео
  pipe = InferencePipeline.from_config("configs/combined_t2i_upscale_i2v.yaml", device="cuda")
  result = pipe(prompt="a cat on the beach", num_steps=28, seed=42)
  video = result.video  # или result.images на промежуточных выходах по соглашению
  ```
- Под капотом: одиночный граф выполняется как сейчас; составной пайплайн — последовательный запуск стадий с передачей выходов предыдущей стадии на входы следующей. Единый класс `InferencePipeline` (при рефакторинге — переименование/обёртка текущего `Pipeline`) поддерживает оба варианта; точки входа: `from_config`, `from_pretrained`, `from_graph`, `from_workflow`, `from_combined` (или аналог для составного конфига).

### 6.2 TrainingPipeline

- **Назначение:** единственный высокоуровневый класс для обучения, универсальный для всего фреймворка — в том числе для **одиночного** графа и для **комбинированного (составного)** пайплайна.
- **Инициализация** (один из способов):
  - из конфигурации графа (YAML/JSON);
  - из конфигурации **составного пайплайна** (YAML/JSON со списком стадий) — с возможностью указать обучаемые стадии и узлы;
  - из pretrained пайплайна (тот же граф или тот же составной пайплайн, что и для инференса, но с помеченными обучаемыми узлами/стадиями);
  - из шаблона обучения (например, «sd15_lora», «sdxl_controlnet», «combined_t2i_upscale»).
- **Интерфейс использования:** один и тот же стиль для одиночного и составного пайплайна, например:
  ```python
  # Одиночный граф
  train_pipe = TrainingPipeline.from_pretrained("runwayml/stable-diffusion-v1-5", train_nodes=["lora_adapter"])
  train_pipe.train(data_path="./data", epochs=10, lr=1e-4)
  train_pipe.save_checkpoint("checkpoints/sd15_lora")

  # Составной пайплайн: обучаем, например, только стадию 0 (txt2img) и узлы LoRA
  train_pipe = TrainingPipeline.from_config("configs/combined_t2i_upscale_i2v.yaml", train_stages=[0], train_nodes=["lora_adapter"])
  train_pipe.train(data_path="./data", epochs=10, lr=1e-4)
  train_pipe.save_checkpoint("checkpoints/combined_stage0_lora")
  ```
- Должна быть возможность указать: какие **стадии** составного пайплайна обучать (`train_stages`), какие **узлы** внутри стадий (`train_nodes`, в т.ч. с префиксом стадии при необходимости), режим (full finetune, только adapter, только inner module и т.д.). Обучение всего комбинированного пайплайна (все обучаемые блоки всех стадий) также должно поддерживаться через тот же класс.

### 6.3 Уточнение по текущей реализации

- Текущий класс `Pipeline` в `pipeline.py` по смыслу соответствует InferencePipeline (from_pretrained, from_template, from_graph, __call__). Рекомендуется:
  - ввести явное имя `InferencePipeline` (избавиться от использования Pipeline);
  - добавить класс `TrainingPipeline` с инициализацией из графа/претрена/шаблона и методом `train(...)`, внутри использующий существующий `DiffusionTrainer` и `GraphTrainer` по графу с выбранными trainable узлами.

---

## 7. Интеграции и деплой

- **User-trained models:** загрузка своих весов и конфигов через тот же граф и те же форматы (YAML графа + веса в safetensors/pt).
- **Diffusers:** текущая интеграция (DiffusersBridge, load_from_diffusers, маппинг scheduler → solver) сохраняется и дорабатывается так, чтобы любой совместимый пайплайн Diffusers конвертировался в граф YggDrasil (в т.ч. один Solver вместо отдельного Scheduler).
- **ComfyUI / Automatic1111:** по возможности — импорт workflow (ComfyUI), совместимость форматов; приоритет ниже первой очереди моделей.
- **Деплой:** возможность развернуть весь фреймворк (или инференс/обучение) на любой удалённой платформе (endpoint, облако). Текущие модули в `deployment/` (Docker, RunPod, Vast.ai, Modal) сохранить и при необходимости обобщить под единый интерфейс деплоя.

---

## 8. Этапы реализации (рекомендуемый порядок)

### Фаза 1: Абстракции и базовый блок

1. Зафиксировать и при необходимости рефакторить **AbstractBaseBlock** (единый базовый класс), привести все существующие абстракции (Backbone, Codec, Conditioner, Guidance, Solver, Adapter) к наследованию от него.
2. Ввести **AbstractInnerModule** (встраивается в сам процесс деноайзинга) и **AbstractOuterModule** (обёртка над внешней моделью: face recognition, object detector и т.д.); реализовать 1–2 примера (ControlNet как Inner, детектор/классификатор как Outer). Detailer- и Upscaler-пайплайны реализовывать как **AbstractStage**, а не как блок Outer.
3. Ввести **AbstractProcessor** (пред- и постобработка данных).
4. Ввести **AbstractStage** (одна стадия пайплайна = граф блоков); многостадийный пайплайн = цепочка AbstractStage. Prior-стадию (Kandinsky, Cascade) представлять первым AbstractStage без отдельного типа блока Prior. MotionAdapter реализовать существующими блоками (Inner/Adapter).
5. Объединить **Scheduler с Solver**: убрать отдельный тип «scheduler», все расписания и шаги — внутри реализаций AbstractSolver; обновить DiffusersBridge и графы.

### Фаза 2: Граф и автоопределение ролей

6. Доработать **ComputeGraph**: добавление узла по типу с автоопределением роли (в т.ч. processor) и автоматическим подключением к нужным портам/входам графа.
7. Реализовать **правила подключения** для ролей: inner → backbone.adapter_features (внутри цикла деноайзинга); outer → до/после выхода стадии; processor → pre/post в стадии; conditioner → цепочка condition; solver — внутри цикла деноайзинга.
8. Конфигурация графа YAML/JSON: полная сериализация/десериализация, сохранение workflow; конфиг многостадийного пайплайна (цепочка AbstractStage).

### Фаза 3: Высокоуровневые API и многостадийные пайплайны

9. Ввести **InferencePipeline** (на базе текущего Pipeline), унифицировать точки входа: from_config, from_pretrained, from_graph, from_workflow, from_combined (цепочка AbstractStage).
10. Реализовать **TrainingPipeline** с инициализацией из графа/претрена/шаблона и методом train(..., train_nodes=..., train_stages=...), интеграция с существующим тренером.
11. Реализовать **многостадийный пайплайн** как цепочку AbstractStage: модель данных (список стадий + маппинг выход→вход), конфиг YAML/JSON, последовательное выполнение. Единый вызов **InferencePipeline** для одиночного и многостадийного случая.
12. Реализовать **обучение многостадийного пайплайна** в **TrainingPipeline**: train_stages / train_nodes, проход градиентов через стадии, сохранение чекпоинтов.

### Фаза 4: Модели и обучение

13. Обеспечить полную поддержку **SD 1.5, SDXL, FLUX.1, FLUX.2 Klein, SD3** (шаблоны графов, тесты, документация); при необходимости — Kandinsky, Stable Cascade как два AbstractStage.
14. Обучение: выбор trainable узлов и стадий, multi-LoRA, сохранение/загрузка чекпоинтов и адаптеров.

### Фаза 5: Интеграции и деплой

15. Стабилизация интеграции Diffusers (включая единый Solver).
16. Деплой: проверка и при необходимости доработка deployment под единый интерфейс (endpoint, облако).

---

## 9. Критерии приёмки (сводка)

| № | Критерий |
|---|----------|
| 1 | Все блоки в коде наследуются от AbstractBaseBlock. |
| 2 | Реализованы и зарегистрированы абстракции: Backbone, Codec, Conditioner, Guidance, Solver (с объединённой логикой Scheduler), Adapter, InnerModule, OuterModule, **Processor**; многостадийный пайплайн как цепочка **AbstractStage** (prior-стадия = первый AbstractStage без отдельного типа блока Prior). |
| 3 | В графе нет отдельного типа «Scheduler» — только Solver. |
| 4 | **add_node:** вызов `add_node(type="...")` — достаточно; граф автоматически определяет роль и место подключения. **add_stage:** стадии могут самоопределять свою последовательность по совместимости портов. Detailer/Upscaler — стадии (AbstractStage). |
| 5 | Любой диффузионный пайплайн представляется графом с произвольной конфигурацией из этих компонентов. |
| 6 | Реализованы классы InferencePipeline и TrainingPipeline с инициализацией из конфига/претрена/графа/шаблона и простым API («в несколько строк»). |
| 7 | Поддержка обучения любых обучаемых блоков с возможностью выбора обучаемых узлов и multi-LoRA. |
| 8 | Работают шаблоны/тесты для SD 1.5, SDXL, FLUX.1, FLUX.2 Klein, SD3. |
| 9 | Сохранена и при необходимости усилена поддержка Diffusers и деплоя на удалённые платформы. |
| 10 | Реализовано **комбинирование графов**: составной пайплайн (например, text→image→upscale→image-to-video) задаётся конфигом, запускается через **InferencePipeline** одним вызовом. |
| 11 | Реализовано **обучение комбинированного пайплайна** через **TrainingPipeline**: выбор обучаемых стадий и узлов, сохранение чекпоинтов по стадиям или общее. |
| 12 | Обеспечена **универсальность**: поддержка любых модальностей и диффузионных решений; возможность регистрировать **собственную модальность**, **собственную модель**, **собственный пайплайн** и **обучить** любой обучаемый блок/стадию/пайплайн через единый API. |

---

## 10. Логическая согласованность и упрощения

- **Один принцип:** «блок = узел графа» на всех уровнях (блоки в стадии, стадии в пайплайне). Нет исключений: Scheduler слит с Solver, Prior — первая стадия, Detailer/Upscaler — стадии, MotionAdapter — существующие блоки.
- **Два графа, один интерфейс:** граф стадии (узлы = блоки) и граф пайплайна (узлы = стадии) дают единую модель; пользователь работает с одним пайплайном и одним вызовом (InferencePipeline / TrainingPipeline).
- **Упрощение:** фиксированный набор абстракций уровня 1 (Backbone, Codec, Conditioner, Guidance, Solver, Adapter, Inner, Outer, Processor) покрывает все известные и будущие диффузионные сценарии без введения новых типов узлов; новые возможности добавляются реализациями, а не новыми абстракциями.
- **Гибкость без усложнения ядра:** собственная модальность, модель и пайплайн реализуются через регистрацию и наследование абстракций; ядро не раздувается.

---

## 11. Глоссарий

- **AbstractBaseBlock (Block)** — базовый кирпичик фреймворка; любой блок наследуется от него и может быть **узлом в графе**. Идея блока и идея графа объединены: граф составляется из блоков-узлов.
- **AbstractInnerModule** — модуль, встраиваемый **в сам процесс деноайзинга** (внутри цикла обратной диффузии); например ControlNet, T2I-Adapter.
- **AbstractOuterModule** — обёртка над **внешней моделью** (face recognition, object detector, classifier и т.д.), подключаемая к пайплайну «сбоку». Detailer- и Upscaler-пайплайны задаются как **AbstractStage**, а не как OuterModule.
- **AbstractProcessor** — пред- и постобработка данных (pre/post-processing) в графе.
- **AbstractStage** — граф блоков уровня 1 (одна стадия пайплайна). Сама AbstractStage выступает **узлом в графе пайплайна**. Пайплайн = граф, узлы которого — AbstractStage; каждый такой узел — граф блоков. Prior-, Detailer-, Upscaler-пайплайны задаются как AbstractStage.
- **Solver** — единая абстракция для шага обратной диффузии и расписания шагов (объединённый Scheduler + step logic).
- **InferencePipeline / TrainingPipeline** — интерфейс пользователя: выполнение **единого графа**, узлы которого — AbstractStage (каждая стадия — граф блоков). Вызов в несколько строк.
- **ComputeGraph** — граф вычислений: узлы = блоки (или, на верхнем уровне, стадии); рёбра = порты/связи; конфигурируется YAML/JSON.
- **Составной (многостадийный) пайплайн** — цепочка AbstractStage; выход стадии N → вход стадии N+1. Запуск через InferencePipeline, обучение через TrainingPipeline.
- **MotionAdapter** — реализуется существующими блоками (AbstractInnerModule или AbstractAdapter), отдельная абстракция не вводится.

---

*Документ предназначен для использования как техническое задание на рефакторинг и развитие фреймворка YggDrasil. Версия 1.2.*
